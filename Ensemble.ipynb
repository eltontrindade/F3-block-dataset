{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from unet0 import UNet as UNet0\n",
    "from unet1 import UNet as UNet1\n",
    "from unet2 import UNet as UNet2\n",
    "\n",
    "\n",
    "\n",
    "redes=[UNet0, UNet1, UNet2]\n",
    "redes[1](4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ``converters`` are currently experimental. It may not support operations including (but not limited to) Functions in ``torch.nn.functional`` that involved data dimension\n",
      "UNet(\n",
      "  (enc1): _EncoderBlock(\n",
      "    (encode): Sequential(\n",
      "      (0): Conv3d(1, 64, kernel_size=[1, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1])\n",
      "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1])\n",
      "      (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (enc2): _EncoderBlock(\n",
      "    (encode): Sequential(\n",
      "      (0): Conv3d(64, 128, kernel_size=[1, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1])\n",
      "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1])\n",
      "      (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (dec1): _DecoderBlock(\n",
      "    (decode): Sequential(\n",
      "      (0): Conv3d(192, 64, kernel_size=[1, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1])\n",
      "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv3d(64, 32, kernel_size=[1, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1])\n",
      "      (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (interpolate): Upsample(scale_factor=2.0, mode=trilinear)\n",
      "  (final): Conv3d(32, 4, kernel_size=[1, 1, 1], stride=(1, 1, 1), padding=[0, 0, 0])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import fire\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from poc_dataset_ACS import BaseDatasetVoxel\n",
    "from mylib.loss import soft_cross_entropy_loss\n",
    "from mylib.utils import MultiAverageMeter, save_model, log_results, to_var, set_seed, \\\n",
    "        to_device, initialize, categorical_to_one_hot, copy_file_backup, redirect_stdout\n",
    "from poc_config_2dpre import POCVoxelConfig as cfg\n",
    "from poc_config_2dpre import POCVoxelEnv as env\n",
    "\n",
    "from unet import UNet\n",
    "from acsconv.models import ACSUNet\n",
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "\n",
    "from mylib.metrics import cal_batch_iou, cal_batch_dice, AUROC_per_case\n",
    "from mylib.loss import soft_dice_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from unet0 import UNet as UNet0\n",
    "from unet1 import UNet as UNet1\n",
    "from unet2 import UNet as UNet2\n",
    "\n",
    "groupmodel=[]\n",
    "\n",
    "redes=[UNet0, UNet1, UNet2]\n",
    "num_classes=4\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    shape_cp= r'C:\\Users\\admin\\Desktop\\cnn-facies-classifier-master\\RESULTADOS_EQM\\CHANNEL'+ format(i)+ r'\\TRAIN_2D\\model.dat'\n",
    "    shape_cp = torch.load(shape_cp)\n",
    "    model= redes[i](num_classes)\n",
    "    #print(shape_cp.keys())\n",
    "    #state_dict_2d=shape_cp.state_dict()\n",
    "    for key in list(shape_cp.keys()):\n",
    "        #print(key)\n",
    "        #print(shape_cp[key].shape)\n",
    "        if shape_cp[key].dim()==4:\n",
    "            #print(key)\n",
    "            shape_cp[key] = shape_cp[key].unsqueeze(i-3)\n",
    "            #print(shape_cp[key].shape)    \n",
    "    \n",
    "    shape_cp.popitem()\n",
    "    shape_cp.popitem()\n",
    "    #print(shape_cp.keys)\n",
    "    model.load_state_dict(shape_cp, strict=False)\n",
    " \n",
    "    groupmodel.append(model)\n",
    "    \n",
    "print(groupmodel[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add code root path (with `mylib`, 'acsconv').\n",
      "UNet(\n",
      "  (enc1): _EncoderBlock(\n",
      "    (encode): Sequential(\n",
      "      (0): Conv3d(1, 64, kernel_size=[3, 3, 1], stride=(1, 1, 1), padding=[1, 1, 0])\n",
      "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv3d(64, 64, kernel_size=[3, 3, 1], stride=(1, 1, 1), padding=[1, 1, 0])\n",
      "      (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (enc2): _EncoderBlock(\n",
      "    (encode): Sequential(\n",
      "      (0): Conv3d(64, 128, kernel_size=[3, 3, 1], stride=(1, 1, 1), padding=[1, 1, 0])\n",
      "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv3d(128, 128, kernel_size=[3, 3, 1], stride=(1, 1, 1), padding=[1, 1, 0])\n",
      "      (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (dec1): _DecoderBlock(\n",
      "    (decode): Sequential(\n",
      "      (0): Conv3d(192, 64, kernel_size=[3, 3, 1], stride=(1, 1, 1), padding=[1, 1, 0])\n",
      "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv3d(64, 32, kernel_size=[3, 3, 1], stride=(1, 1, 1), padding=[1, 1, 0])\n",
      "      (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (interpolate): Upsample(scale_factor=2.0, mode=trilinear)\n",
      "  (final): Conv3d(32, 4, kernel_size=[1, 1, 1], stride=(1, 1, 1), padding=[0, 0, 0])\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2506: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tIter: [1/83]\tTime 4.820 (4.820)\tLoss 0.7623 (0.7623)\tIOU 0.1105 (0.1105)\tDICE 0.1936 (0.1936)\n",
      "Epoch: [1/50]\tIter: [33/83]\tTime 0.063 (0.207)\tLoss 0.3788 (0.5067)\tIOU 0.6264 (0.4793)\tDICE 0.7460 (0.6215)\n",
      "Test\tIter: [1/17]\tTime 3.811 (3.811)\tLoss 0.3732 (0.3732)\tIOU 0.5933 (0.5933)\tDICE 0.6661 (0.6661)\n",
      "New best dice: 0.7753\n",
      "Epoch: [2/50]\tIter: [1/83]\tTime 3.519 (3.519)\tLoss 0.2385 (0.2385)\tIOU 0.7210 (0.7210)\tDICE 0.8200 (0.8200)\n",
      "Epoch: [2/50]\tIter: [33/83]\tTime 0.064 (0.168)\tLoss 0.2066 (0.2318)\tIOU 0.7373 (0.7199)\tDICE 0.8325 (0.8195)\n",
      "Epoch: [2/50]\tIter: [65/83]\tTime 0.064 (0.116)\tLoss 0.1825 (0.2142)\tIOU 0.7491 (0.7308)\tDICE 0.8418 (0.8275)\n",
      "Epoch: [2/50]\tIter: [83/83]\tTime 0.050 (0.105)\tLoss 0.1723 (0.2063)\tIOU 0.7624 (0.7353)\tDICE 0.8527 (0.8309)\n",
      "Test\tIter: [1/17]\tTime 3.505 (3.505)\tLoss 0.2372 (0.2372)\tIOU 0.7303 (0.7303)\tDICE 0.8069 (0.8069)\n",
      "New best dice: 0.8417\n",
      "Epoch: [3/50]\tIter: [1/83]\tTime 3.468 (3.468)\tLoss 0.1689 (0.1689)\tIOU 0.7655 (0.7655)\tDICE 0.8551 (0.8551)\n",
      "Epoch: [3/50]\tIter: [35/83]\tTime 0.060 (0.161)\tLoss 0.1506 (0.1646)\tIOU 0.7814 (0.7654)\tDICE 0.8656 (0.8532)\n",
      "Epoch: [3/50]\tIter: [83/83]\tTime 0.050 (0.104)\tLoss 0.1874 (0.1575)\tIOU 0.7539 (0.7705)\tDICE 0.8381 (0.8569)\n",
      "Test\tIter: [1/17]\tTime 3.573 (3.573)\tLoss 0.1845 (0.1845)\tIOU 0.7948 (0.7948)\tDICE 0.8682 (0.8682)\n",
      "New best dice: 0.8642\n",
      "Epoch: [4/50]\tIter: [1/83]\tTime 3.476 (3.476)\tLoss 0.1499 (0.1499)\tIOU 0.7761 (0.7761)\tDICE 0.8613 (0.8613)\n",
      "Test\tIter: [1/17]\tTime 3.586 (3.586)\tLoss 0.1682 (0.1682)\tIOU 0.7748 (0.7748)\tDICE 0.8491 (0.8491)\n",
      "New best dice: 0.8729\n",
      "Epoch: [5/50]\tIter: [1/83]\tTime 3.404 (3.404)\tLoss 0.1300 (0.1300)\tIOU 0.8009 (0.8009)\tDICE 0.8799 (0.8799)\n",
      "Epoch: [5/50]\tIter: [34/83]\tTime 0.062 (0.162)\tLoss 0.1196 (0.1264)\tIOU 0.8117 (0.8074)\tDICE 0.8871 (0.8840)\n",
      "Epoch: [5/50]\tIter: [83/83]\tTime 0.049 (0.103)\tLoss 0.1104 (0.1226)\tIOU 0.8307 (0.8129)\tDICE 0.9002 (0.8880)\n",
      "Test\tIter: [1/17]\tTime 3.553 (3.553)\tLoss 0.1347 (0.1347)\tIOU 0.8296 (0.8296)\tDICE 0.8947 (0.8947)\n",
      "New best dice: 0.8956\n",
      "Epoch: [6/50]\tIter: [1/83]\tTime 3.483 (3.483)\tLoss 0.1169 (0.1169)\tIOU 0.8210 (0.8210)\tDICE 0.8935 (0.8935)\n",
      "Epoch: [6/50]\tIter: [34/83]\tTime 0.062 (0.164)\tLoss 0.1119 (0.1136)\tIOU 0.8281 (0.8260)\tDICE 0.8996 (0.8973)\n",
      "Epoch: [6/50]\tIter: [65/83]\tTime 0.063 (0.115)\tLoss 0.1120 (0.1156)\tIOU 0.8212 (0.8202)\tDICE 0.8940 (0.8933)\n",
      "Epoch: [6/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.1096 (0.1153)\tIOU 0.8306 (0.8204)\tDICE 0.9010 (0.8934)\n",
      "Test\tIter: [1/17]\tTime 3.595 (3.595)\tLoss 0.1247 (0.1247)\tIOU 0.8314 (0.8314)\tDICE 0.8960 (0.8960)\n",
      "New best dice: 0.8999\n",
      "Epoch: [7/50]\tIter: [1/83]\tTime 3.441 (3.441)\tLoss 0.1064 (0.1064)\tIOU 0.8296 (0.8296)\tDICE 0.8992 (0.8992)\n",
      "Epoch: [7/50]\tIter: [34/83]\tTime 0.061 (0.162)\tLoss 0.1051 (0.1059)\tIOU 0.8432 (0.8369)\tDICE 0.9097 (0.9048)\n",
      "Test\tIter: [1/17]\tTime 3.602 (3.602)\tLoss 0.1136 (0.1136)\tIOU 0.8558 (0.8558)\tDICE 0.9139 (0.9139)\n",
      "New best dice: 0.9139\n",
      "Epoch: [8/50]\tIter: [1/83]\tTime 3.455 (3.455)\tLoss 0.0980 (0.0980)\tIOU 0.8502 (0.8502)\tDICE 0.9137 (0.9137)\n",
      "Epoch: [8/50]\tIter: [32/83]\tTime 0.066 (0.170)\tLoss 0.0871 (0.0953)\tIOU 0.8604 (0.8546)\tDICE 0.9200 (0.9166)\n",
      "Epoch: [8/50]\tIter: [34/83]\tTime 0.062 (0.164)\tLoss 0.0907 (0.0953)\tIOU 0.8620 (0.8548)\tDICE 0.9216 (0.9167)\n",
      "Epoch: [8/50]\tIter: [65/83]\tTime 0.063 (0.115)\tLoss 0.0929 (0.0948)\tIOU 0.8628 (0.8558)\tDICE 0.9223 (0.9174)\n",
      "Test\tIter: [1/17]\tTime 3.589 (3.589)\tLoss 0.1164 (0.1164)\tIOU 0.8374 (0.8374)\tDICE 0.9003 (0.9003)\n",
      "Current best dice: 0.9139\n",
      "Epoch: [9/50]\tIter: [1/83]\tTime 3.465 (3.465)\tLoss 0.0908 (0.0908)\tIOU 0.8578 (0.8578)\tDICE 0.9185 (0.9185)\n",
      "Epoch: [9/50]\tIter: [34/83]\tTime 0.062 (0.164)\tLoss 0.0944 (0.0903)\tIOU 0.8571 (0.8617)\tDICE 0.9187 (0.9213)\n",
      "Epoch: [9/50]\tIter: [65/83]\tTime 0.064 (0.116)\tLoss 0.0971 (0.0910)\tIOU 0.8530 (0.8578)\tDICE 0.9158 (0.9188)\n",
      "Test\tIter: [1/17]\tTime 3.585 (3.585)\tLoss 0.1037 (0.1037)\tIOU 0.8482 (0.8482)\tDICE 0.9082 (0.9082)\n",
      "New best dice: 0.9159\n",
      "Epoch: [10/50]\tIter: [1/83]\tTime 3.461 (3.461)\tLoss 0.0901 (0.0901)\tIOU 0.8662 (0.8662)\tDICE 0.9244 (0.9244)\n",
      "Epoch: [10/50]\tIter: [34/83]\tTime 0.061 (0.163)\tLoss 0.0869 (0.0884)\tIOU 0.8654 (0.8604)\tDICE 0.9237 (0.9204)\n",
      "Epoch: [10/50]\tIter: [63/83]\tTime 0.065 (0.117)\tLoss 0.0804 (0.0862)\tIOU 0.8825 (0.8648)\tDICE 0.9347 (0.9233)\n",
      "Epoch: [10/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.0822 (0.0860)\tIOU 0.8789 (0.8656)\tDICE 0.9320 (0.9237)\n",
      "Epoch: [10/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0849 (0.0845)\tIOU 0.8817 (0.8688)\tDICE 0.9341 (0.9258)\n",
      "Test\tIter: [1/17]\tTime 3.599 (3.599)\tLoss 0.0914 (0.0914)\tIOU 0.8924 (0.8924)\tDICE 0.9385 (0.9385)\n",
      "New best dice: 0.9243\n",
      "Epoch: [11/50]\tIter: [1/83]\tTime 3.432 (3.432)\tLoss 0.0749 (0.0749)\tIOU 0.8891 (0.8891)\tDICE 0.9385 (0.9385)\n",
      "Epoch: [11/50]\tIter: [33/83]\tTime 0.064 (0.166)\tLoss 0.0792 (0.0775)\tIOU 0.8773 (0.8840)\tDICE 0.9313 (0.9353)\n",
      "Epoch: [11/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.0725 (0.0766)\tIOU 0.8951 (0.8857)\tDICE 0.9423 (0.9364)\n",
      "Test\tIter: [1/17]\tTime 3.616 (3.616)\tLoss 0.0865 (0.0865)\tIOU 0.8912 (0.8912)\tDICE 0.9378 (0.9378)\n",
      "New best dice: 0.9303\n",
      "Epoch: [12/50]\tIter: [1/83]\tTime 3.459 (3.459)\tLoss 0.0788 (0.0788)\tIOU 0.8887 (0.8887)\tDICE 0.9385 (0.9385)\n",
      "Epoch: [12/50]\tIter: [34/83]\tTime 0.061 (0.164)\tLoss 0.0748 (0.0759)\tIOU 0.8888 (0.8844)\tDICE 0.9383 (0.9356)\n",
      "Epoch: [12/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.0725 (0.0732)\tIOU 0.9026 (0.8887)\tDICE 0.9468 (0.9382)\n",
      "Epoch: [12/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0781 (0.0730)\tIOU 0.8795 (0.8895)\tDICE 0.9333 (0.9388)\n",
      "Test\tIter: [1/17]\tTime 3.537 (3.537)\tLoss 0.0726 (0.0726)\tIOU 0.9178 (0.9178)\tDICE 0.9546 (0.9546)\n",
      "New best dice: 0.9428\n",
      "Epoch: [13/50]\tIter: [1/83]\tTime 3.463 (3.463)\tLoss 0.0698 (0.0698)\tIOU 0.8944 (0.8944)\tDICE 0.9418 (0.9418)\n",
      "Epoch: [13/50]\tIter: [32/83]\tTime 0.065 (0.170)\tLoss 0.0663 (0.0687)\tIOU 0.9103 (0.8994)\tDICE 0.9513 (0.9448)\n",
      "Epoch: [13/50]\tIter: [34/83]\tTime 0.062 (0.164)\tLoss 0.0635 (0.0684)\tIOU 0.9022 (0.8995)\tDICE 0.9461 (0.9449)\n",
      "Epoch: [13/50]\tIter: [65/83]\tTime 0.063 (0.116)\tLoss 0.0642 (0.0679)\tIOU 0.9066 (0.8999)\tDICE 0.9493 (0.9451)\n",
      "Test\tIter: [1/17]\tTime 3.569 (3.569)\tLoss 0.1176 (0.1176)\tIOU 0.7965 (0.7965)\tDICE 0.8764 (0.8764)\n",
      "Current best dice: 0.9428\n",
      "Epoch: [14/50]\tIter: [1/83]\tTime 3.422 (3.422)\tLoss 0.0663 (0.0663)\tIOU 0.8942 (0.8942)\tDICE 0.9417 (0.9417)\n",
      "Epoch: [14/50]\tIter: [65/83]\tTime 0.063 (0.115)\tLoss 0.0583 (0.0649)\tIOU 0.9148 (0.9022)\tDICE 0.9539 (0.9465)\n",
      "Epoch: [14/50]\tIter: [83/83]\tTime 0.050 (0.104)\tLoss 0.0667 (0.0644)\tIOU 0.8996 (0.9034)\tDICE 0.9453 (0.9472)\n",
      "Test\tIter: [1/17]\tTime 3.598 (3.598)\tLoss 0.0771 (0.0771)\tIOU 0.8899 (0.8899)\tDICE 0.9370 (0.9370)\n",
      "New best dice: 0.9443\n",
      "Epoch: [15/50]\tIter: [1/83]\tTime 3.456 (3.456)\tLoss 0.0621 (0.0621)\tIOU 0.9060 (0.9060)\tDICE 0.9488 (0.9488)\n",
      "Epoch: [15/50]\tIter: [33/83]\tTime 0.064 (0.167)\tLoss 0.0579 (0.0659)\tIOU 0.9018 (0.8942)\tDICE 0.9461 (0.9417)\n",
      "Epoch: [15/50]\tIter: [65/83]\tTime 0.064 (0.116)\tLoss 0.0614 (0.0650)\tIOU 0.9099 (0.8980)\tDICE 0.9510 (0.9440)\n",
      "Epoch: [15/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.0617 (0.0649)\tIOU 0.9125 (0.8984)\tDICE 0.9527 (0.9442)\n",
      "Epoch: [15/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0532 (0.0639)\tIOU 0.9221 (0.9006)\tDICE 0.9581 (0.9456)\n",
      "Test\tIter: [1/17]\tTime 3.553 (3.553)\tLoss 0.0628 (0.0628)\tIOU 0.9321 (0.9321)\tDICE 0.9632 (0.9632)\n",
      "New best dice: 0.9503\n",
      "Epoch: [16/50]\tIter: [1/83]\tTime 3.463 (3.463)\tLoss 0.0654 (0.0654)\tIOU 0.9067 (0.9067)\tDICE 0.9492 (0.9492)\n",
      "Epoch: [16/50]\tIter: [34/83]\tTime 0.062 (0.164)\tLoss 0.0615 (0.0605)\tIOU 0.8953 (0.9065)\tDICE 0.9423 (0.9491)\n",
      "Epoch: [16/50]\tIter: [65/83]\tTime 0.064 (0.116)\tLoss 0.0547 (0.0599)\tIOU 0.9103 (0.9073)\tDICE 0.9512 (0.9495)\n",
      "Test\tIter: [1/17]\tTime 3.545 (3.545)\tLoss 0.0583 (0.0583)\tIOU 0.9475 (0.9475)\tDICE 0.9720 (0.9720)\n",
      "New best dice: 0.9528\n",
      "Epoch: [17/50]\tIter: [1/83]\tTime 3.463 (3.463)\tLoss 0.0617 (0.0617)\tIOU 0.9107 (0.9107)\tDICE 0.9517 (0.9517)\n",
      "Epoch: [17/50]\tIter: [33/83]\tTime 0.063 (0.168)\tLoss 0.0662 (0.0557)\tIOU 0.8947 (0.9167)\tDICE 0.9425 (0.9551)\n",
      "Epoch: [17/50]\tIter: [83/83]\tTime 0.050 (0.104)\tLoss 0.0550 (0.0551)\tIOU 0.9074 (0.9171)\tDICE 0.9496 (0.9553)\n",
      "Test\tIter: [1/17]\tTime 3.565 (3.565)\tLoss 0.0535 (0.0535)\tIOU 0.9359 (0.9359)\tDICE 0.9654 (0.9654)\n",
      "New best dice: 0.9551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18/50]\tIter: [1/83]\tTime 3.435 (3.435)\tLoss 0.0521 (0.0521)\tIOU 0.9147 (0.9147)\tDICE 0.9541 (0.9541)\n",
      "Epoch: [18/50]\tIter: [34/83]\tTime 0.062 (0.163)\tLoss 0.0444 (0.0520)\tIOU 0.9360 (0.9231)\tDICE 0.9660 (0.9587)\n",
      "Epoch: [18/50]\tIter: [67/83]\tTime 0.062 (0.113)\tLoss 0.0666 (0.0585)\tIOU 0.8926 (0.9077)\tDICE 0.9410 (0.9494)\n",
      "Epoch: [18/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0555 (0.0580)\tIOU 0.9119 (0.9084)\tDICE 0.9522 (0.9499)\n",
      "Test\tIter: [1/17]\tTime 3.578 (3.578)\tLoss 0.0608 (0.0608)\tIOU 0.9254 (0.9254)\tDICE 0.9591 (0.9591)\n",
      "Current best dice: 0.9551\n",
      "Epoch: [19/50]\tIter: [1/83]\tTime 3.479 (3.479)\tLoss 0.0463 (0.0463)\tIOU 0.9280 (0.9280)\tDICE 0.9613 (0.9613)\n",
      "Epoch: [19/50]\tIter: [31/83]\tTime 0.068 (0.174)\tLoss 0.0458 (0.0520)\tIOU 0.9240 (0.9189)\tDICE 0.9591 (0.9563)\n",
      "Epoch: [19/50]\tIter: [33/83]\tTime 0.064 (0.167)\tLoss 0.0461 (0.0519)\tIOU 0.9274 (0.9194)\tDICE 0.9612 (0.9565)\n",
      "Epoch: [19/50]\tIter: [61/83]\tTime 0.068 (0.119)\tLoss 0.0444 (0.0516)\tIOU 0.9375 (0.9211)\tDICE 0.9669 (0.9576)\n",
      "Epoch: [19/50]\tIter: [65/83]\tTime 0.063 (0.116)\tLoss 0.0478 (0.0516)\tIOU 0.9232 (0.9213)\tDICE 0.9588 (0.9577)\n",
      "Epoch: [19/50]\tIter: [83/83]\tTime 0.050 (0.105)\tLoss 0.0391 (0.0510)\tIOU 0.9446 (0.9225)\tDICE 0.9707 (0.9584)\n",
      "Test\tIter: [1/17]\tTime 3.579 (3.579)\tLoss 0.0585 (0.0585)\tIOU 0.9152 (0.9152)\tDICE 0.9530 (0.9530)\n",
      "Current best dice: 0.9551\n",
      "Epoch: [20/50]\tIter: [1/83]\tTime 3.446 (3.446)\tLoss 0.0470 (0.0470)\tIOU 0.9251 (0.9251)\tDICE 0.9600 (0.9600)\n",
      "Epoch: [20/50]\tIter: [65/83]\tTime 0.063 (0.116)\tLoss 0.0477 (0.0494)\tIOU 0.9296 (0.9248)\tDICE 0.9626 (0.9597)\n",
      "Epoch: [20/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0563 (0.0495)\tIOU 0.9007 (0.9236)\tDICE 0.9457 (0.9590)\n",
      "Test\tIter: [1/17]\tTime 3.599 (3.599)\tLoss 0.0612 (0.0612)\tIOU 0.9145 (0.9145)\tDICE 0.9527 (0.9527)\n",
      "Current best dice: 0.9551\n",
      "Epoch: [21/50]\tIter: [1/83]\tTime 3.495 (3.495)\tLoss 0.0486 (0.0486)\tIOU 0.9138 (0.9138)\tDICE 0.9529 (0.9529)\n",
      "Epoch: [21/50]\tIter: [33/83]\tTime 0.063 (0.168)\tLoss 0.0513 (0.0506)\tIOU 0.9235 (0.9172)\tDICE 0.9590 (0.9553)\n",
      "Epoch: [21/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.0412 (0.0479)\tIOU 0.9399 (0.9242)\tDICE 0.9683 (0.9593)\n",
      "Test\tIter: [1/17]\tTime 3.609 (3.609)\tLoss 0.0709 (0.0709)\tIOU 0.8900 (0.8900)\tDICE 0.9393 (0.9393)\n",
      "Current best dice: 0.9551\n",
      "Epoch: [22/50]\tIter: [1/83]\tTime 3.456 (3.456)\tLoss 0.0478 (0.0478)\tIOU 0.9257 (0.9257)\tDICE 0.9603 (0.9603)\n",
      "Epoch: [22/50]\tIter: [61/83]\tTime 0.067 (0.119)\tLoss 0.0384 (0.0440)\tIOU 0.9370 (0.9331)\tDICE 0.9666 (0.9644)\n",
      "Epoch: [22/50]\tIter: [63/83]\tTime 0.066 (0.117)\tLoss 0.0468 (0.0441)\tIOU 0.9258 (0.9329)\tDICE 0.9603 (0.9643)\n",
      "Epoch: [22/50]\tIter: [65/83]\tTime 0.064 (0.116)\tLoss 0.0429 (0.0441)\tIOU 0.9345 (0.9329)\tDICE 0.9653 (0.9643)\n",
      "Epoch: [22/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.0400 (0.0440)\tIOU 0.9370 (0.9329)\tDICE 0.9666 (0.9643)\n",
      "Epoch: [22/50]\tIter: [83/83]\tTime 0.050 (0.105)\tLoss 0.0459 (0.0442)\tIOU 0.9214 (0.9316)\tDICE 0.9577 (0.9636)\n",
      "Test\tIter: [1/17]\tTime 3.600 (3.600)\tLoss 0.0466 (0.0466)\tIOU 0.9385 (0.9385)\tDICE 0.9669 (0.9669)\n",
      "New best dice: 0.9552\n",
      "Epoch: [23/50]\tIter: [1/83]\tTime 3.466 (3.466)\tLoss 0.0497 (0.0497)\tIOU 0.9208 (0.9208)\tDICE 0.9573 (0.9573)\n",
      "Epoch: [23/50]\tIter: [65/83]\tTime 0.063 (0.116)\tLoss 0.0421 (0.0432)\tIOU 0.9376 (0.9318)\tDICE 0.9670 (0.9637)\n",
      "Epoch: [23/50]\tIter: [83/83]\tTime 0.050 (0.104)\tLoss 0.0396 (0.0427)\tIOU 0.9368 (0.9332)\tDICE 0.9665 (0.9645)\n",
      "Test\tIter: [1/17]\tTime 3.593 (3.593)\tLoss 0.0340 (0.0340)\tIOU 0.9729 (0.9729)\tDICE 0.9860 (0.9860)\n",
      "New best dice: 0.9682\n",
      "Epoch: [24/50]\tIter: [1/83]\tTime 3.441 (3.441)\tLoss 0.0379 (0.0379)\tIOU 0.9418 (0.9418)\tDICE 0.9694 (0.9694)\n",
      "Epoch: [24/50]\tIter: [34/83]\tTime 0.062 (0.163)\tLoss 0.0342 (0.0388)\tIOU 0.9453 (0.9406)\tDICE 0.9712 (0.9686)\n",
      "Epoch: [24/50]\tIter: [67/83]\tTime 0.061 (0.114)\tLoss 0.0331 (0.0387)\tIOU 0.9456 (0.9406)\tDICE 0.9713 (0.9686)\n",
      "Test\tIter: [1/17]\tTime 3.635 (3.635)\tLoss 0.0309 (0.0309)\tIOU 0.9778 (0.9778)\tDICE 0.9886 (0.9886)\n",
      "New best dice: 0.9696\n",
      "Epoch: [25/50]\tIter: [1/83]\tTime 3.427 (3.427)\tLoss 0.0403 (0.0403)\tIOU 0.9377 (0.9377)\tDICE 0.9671 (0.9671)\n",
      "Epoch: [25/50]\tIter: [63/83]\tTime 0.066 (0.117)\tLoss 0.0452 (0.0402)\tIOU 0.9320 (0.9361)\tDICE 0.9638 (0.9661)\n",
      "Epoch: [25/50]\tIter: [67/83]\tTime 0.061 (0.114)\tLoss 0.0429 (0.0401)\tIOU 0.9335 (0.9361)\tDICE 0.9647 (0.9661)\n",
      "Test\tIter: [1/17]\tTime 3.596 (3.596)\tLoss 0.0305 (0.0305)\tIOU 0.9732 (0.9732)\tDICE 0.9862 (0.9862)\n",
      "Current best dice: 0.9696\n",
      "Epoch: [26/50]\tIter: [1/83]\tTime 3.459 (3.459)\tLoss 0.0461 (0.0461)\tIOU 0.9323 (0.9323)\tDICE 0.9640 (0.9640)\n",
      "Epoch: [26/50]\tIter: [33/83]\tTime 0.064 (0.167)\tLoss 0.0404 (0.0388)\tIOU 0.9337 (0.9379)\tDICE 0.9648 (0.9671)\n",
      "Test\tIter: [1/17]\tTime 3.576 (3.576)\tLoss 0.0300 (0.0300)\tIOU 0.9770 (0.9770)\tDICE 0.9882 (0.9882)\n",
      "New best dice: 0.9709\n",
      "Epoch: [27/50]\tIter: [1/83]\tTime 3.402 (3.402)\tLoss 0.0348 (0.0348)\tIOU 0.9451 (0.9451)\tDICE 0.9711 (0.9711)\n",
      "Epoch: [27/50]\tIter: [33/83]\tTime 0.064 (0.165)\tLoss 0.0380 (0.0422)\tIOU 0.9380 (0.9304)\tDICE 0.9672 (0.9628)\n",
      "Epoch: [27/50]\tIter: [65/83]\tTime 0.063 (0.115)\tLoss 0.0334 (0.0393)\tIOU 0.9456 (0.9356)\tDICE 0.9714 (0.9657)\n",
      "Epoch: [27/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.0363 (0.0393)\tIOU 0.9422 (0.9357)\tDICE 0.9695 (0.9658)\n",
      "Epoch: [27/50]\tIter: [83/83]\tTime 0.050 (0.104)\tLoss 0.0342 (0.0383)\tIOU 0.9382 (0.9374)\tDICE 0.9672 (0.9668)\n",
      "Test\tIter: [1/17]\tTime 3.614 (3.614)\tLoss 0.0291 (0.0291)\tIOU 0.9713 (0.9713)\tDICE 0.9851 (0.9851)\n",
      "Current best dice: 0.9709\n",
      "Epoch: [28/50]\tIter: [1/83]\tTime 3.406 (3.406)\tLoss 0.0312 (0.0312)\tIOU 0.9440 (0.9440)\tDICE 0.9703 (0.9703)\n",
      "Epoch: [28/50]\tIter: [33/83]\tTime 0.063 (0.165)\tLoss 0.0361 (0.0349)\tIOU 0.9412 (0.9437)\tDICE 0.9689 (0.9703)\n",
      "Epoch: [28/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0359 (0.0342)\tIOU 0.9478 (0.9446)\tDICE 0.9727 (0.9709)\n",
      "Test\tIter: [1/17]\tTime 3.596 (3.596)\tLoss 0.0267 (0.0267)\tIOU 0.9762 (0.9762)\tDICE 0.9877 (0.9877)\n",
      "New best dice: 0.9722\n",
      "Epoch: [29/50]\tIter: [1/83]\tTime 3.497 (3.497)\tLoss 0.0340 (0.0340)\tIOU 0.9462 (0.9462)\tDICE 0.9718 (0.9718)\n",
      "Epoch: [29/50]\tIter: [32/83]\tTime 0.065 (0.172)\tLoss 0.0338 (0.0327)\tIOU 0.9492 (0.9474)\tDICE 0.9734 (0.9724)\n",
      "Epoch: [29/50]\tIter: [67/83]\tTime 0.062 (0.115)\tLoss 0.0333 (0.0323)\tIOU 0.9432 (0.9472)\tDICE 0.9701 (0.9723)\n",
      "Test\tIter: [1/17]\tTime 3.567 (3.567)\tLoss 0.0239 (0.0239)\tIOU 0.9831 (0.9831)\tDICE 0.9914 (0.9914)\n",
      "New best dice: 0.9736\n",
      "Epoch: [30/50]\tIter: [1/83]\tTime 3.452 (3.452)\tLoss 0.0363 (0.0363)\tIOU 0.9459 (0.9459)\tDICE 0.9716 (0.9716)\n",
      "Epoch: [30/50]\tIter: [65/83]\tTime 0.063 (0.115)\tLoss 0.0287 (0.0314)\tIOU 0.9487 (0.9481)\tDICE 0.9731 (0.9728)\n",
      "Epoch: [30/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.0275 (0.0313)\tIOU 0.9520 (0.9482)\tDICE 0.9749 (0.9729)\n",
      "Test\tIter: [1/17]\tTime 3.582 (3.582)\tLoss 0.0231 (0.0231)\tIOU 0.9819 (0.9819)\tDICE 0.9908 (0.9908)\n",
      "Current best dice: 0.9736\n",
      "Epoch: [31/50]\tIter: [1/83]\tTime 3.425 (3.425)\tLoss 0.0334 (0.0334)\tIOU 0.9468 (0.9468)\tDICE 0.9721 (0.9721)\n",
      "Epoch: [31/50]\tIter: [33/83]\tTime 0.064 (0.166)\tLoss 0.0322 (0.0311)\tIOU 0.9442 (0.9472)\tDICE 0.9706 (0.9723)\n",
      "Epoch: [31/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0340 (0.0310)\tIOU 0.9454 (0.9478)\tDICE 0.9714 (0.9726)\n",
      "Test\tIter: [1/17]\tTime 3.585 (3.585)\tLoss 0.0213 (0.0213)\tIOU 0.9845 (0.9845)\tDICE 0.9921 (0.9921)\n",
      "New best dice: 0.9741\n",
      "Epoch: [32/50]\tIter: [1/83]\tTime 3.448 (3.448)\tLoss 0.0306 (0.0306)\tIOU 0.9496 (0.9496)\tDICE 0.9736 (0.9736)\n",
      "Epoch: [32/50]\tIter: [67/83]\tTime 0.061 (0.114)\tLoss 0.0284 (0.0291)\tIOU 0.9482 (0.9505)\tDICE 0.9728 (0.9741)\n",
      "Epoch: [32/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0256 (0.0291)\tIOU 0.9547 (0.9503)\tDICE 0.9764 (0.9740)\n",
      "Test\tIter: [1/17]\tTime 3.483 (3.483)\tLoss 0.0204 (0.0204)\tIOU 0.9819 (0.9819)\tDICE 0.9908 (0.9908)\n",
      "Current best dice: 0.9741\n",
      "Epoch: [33/50]\tIter: [1/83]\tTime 3.429 (3.429)\tLoss 0.0301 (0.0301)\tIOU 0.9475 (0.9475)\tDICE 0.9725 (0.9725)\n",
      "Epoch: [33/50]\tIter: [34/83]\tTime 0.061 (0.163)\tLoss 0.0278 (0.0297)\tIOU 0.9501 (0.9488)\tDICE 0.9739 (0.9732)\n",
      "Test\tIter: [1/17]\tTime 3.667 (3.667)\tLoss 0.0204 (0.0204)\tIOU 0.9828 (0.9828)\tDICE 0.9912 (0.9912)\n",
      "New best dice: 0.9756\n",
      "Epoch: [34/50]\tIter: [1/83]\tTime 3.448 (3.448)\tLoss 0.0285 (0.0285)\tIOU 0.9497 (0.9497)\tDICE 0.9737 (0.9737)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [34/50]\tIter: [67/83]\tTime 0.061 (0.114)\tLoss 0.0309 (0.0282)\tIOU 0.9468 (0.9508)\tDICE 0.9720 (0.9742)\n",
      "Epoch: [34/50]\tIter: [69/83]\tTime 0.060 (0.112)\tLoss 0.0288 (0.0282)\tIOU 0.9482 (0.9507)\tDICE 0.9728 (0.9742)\n",
      "Epoch: [34/50]\tIter: [83/83]\tTime 0.050 (0.104)\tLoss 0.0307 (0.0283)\tIOU 0.9490 (0.9506)\tDICE 0.9733 (0.9742)\n",
      "Test\tIter: [1/17]\tTime 3.565 (3.565)\tLoss 0.0208 (0.0208)\tIOU 0.9755 (0.9755)\tDICE 0.9874 (0.9874)\n",
      "Current best dice: 0.9756\n",
      "Epoch: [35/50]\tIter: [1/83]\tTime 3.522 (3.522)\tLoss 0.0279 (0.0279)\tIOU 0.9487 (0.9487)\tDICE 0.9731 (0.9731)\n",
      "Epoch: [35/50]\tIter: [31/83]\tTime 0.067 (0.175)\tLoss 0.0264 (0.0271)\tIOU 0.9523 (0.9523)\tDICE 0.9751 (0.9751)\n",
      "Test\tIter: [1/17]\tTime 3.627 (3.627)\tLoss 0.0262 (0.0262)\tIOU 0.9663 (0.9663)\tDICE 0.9825 (0.9825)\n",
      "Current best dice: 0.9756\n",
      "Epoch: [36/50]\tIter: [1/83]\tTime 3.509 (3.509)\tLoss 0.0319 (0.0319)\tIOU 0.9441 (0.9441)\tDICE 0.9705 (0.9705)\n",
      "Epoch: [36/50]\tIter: [34/83]\tTime 0.062 (0.165)\tLoss 0.0245 (0.0299)\tIOU 0.9528 (0.9466)\tDICE 0.9753 (0.9719)\n",
      "Epoch: [36/50]\tIter: [67/83]\tTime 0.061 (0.114)\tLoss 0.0321 (0.0291)\tIOU 0.9428 (0.9477)\tDICE 0.9699 (0.9726)\n",
      "Epoch: [36/50]\tIter: [83/83]\tTime 0.050 (0.105)\tLoss 0.0280 (0.0291)\tIOU 0.9498 (0.9479)\tDICE 0.9737 (0.9727)\n",
      "Test\tIter: [1/17]\tTime 3.504 (3.504)\tLoss 0.0183 (0.0183)\tIOU 0.9855 (0.9855)\tDICE 0.9926 (0.9926)\n",
      "Current best dice: 0.9756\n",
      "Epoch: [37/50]\tIter: [1/83]\tTime 3.508 (3.508)\tLoss 0.0295 (0.0295)\tIOU 0.9478 (0.9478)\tDICE 0.9726 (0.9726)\n",
      "Epoch: [37/50]\tIter: [33/83]\tTime 0.063 (0.169)\tLoss 0.0296 (0.0271)\tIOU 0.9481 (0.9509)\tDICE 0.9728 (0.9743)\n",
      "Epoch: [37/50]\tIter: [67/83]\tTime 0.061 (0.115)\tLoss 0.0212 (0.0266)\tIOU 0.9599 (0.9516)\tDICE 0.9792 (0.9747)\n",
      "Epoch: [37/50]\tIter: [69/83]\tTime 0.060 (0.114)\tLoss 0.0226 (0.0265)\tIOU 0.9572 (0.9517)\tDICE 0.9777 (0.9748)\n",
      "Epoch: [37/50]\tIter: [83/83]\tTime 0.049 (0.106)\tLoss 0.0268 (0.0263)\tIOU 0.9485 (0.9521)\tDICE 0.9730 (0.9750)\n",
      "Test\tIter: [1/17]\tTime 3.547 (3.547)\tLoss 0.0155 (0.0155)\tIOU 0.9847 (0.9847)\tDICE 0.9922 (0.9922)\n",
      "New best dice: 0.9772\n",
      "Epoch: [38/50]\tIter: [1/83]\tTime 3.461 (3.461)\tLoss 0.0254 (0.0254)\tIOU 0.9549 (0.9549)\tDICE 0.9765 (0.9765)\n",
      "Epoch: [38/50]\tIter: [65/83]\tTime 0.064 (0.116)\tLoss 0.0251 (0.0248)\tIOU 0.9526 (0.9542)\tDICE 0.9752 (0.9761)\n",
      "Test\tIter: [1/17]\tTime 3.614 (3.614)\tLoss 0.0152 (0.0152)\tIOU 0.9847 (0.9847)\tDICE 0.9922 (0.9922)\n",
      "Current best dice: 0.9772\n",
      "Epoch: [39/50]\tIter: [1/83]\tTime 3.442 (3.442)\tLoss 0.0246 (0.0246)\tIOU 0.9565 (0.9565)\tDICE 0.9774 (0.9774)\n",
      "Epoch: [39/50]\tIter: [33/83]\tTime 0.063 (0.167)\tLoss 0.0282 (0.0255)\tIOU 0.9521 (0.9529)\tDICE 0.9750 (0.9754)\n",
      "Epoch: [39/50]\tIter: [65/83]\tTime 0.063 (0.115)\tLoss 0.0242 (0.0251)\tIOU 0.9522 (0.9536)\tDICE 0.9750 (0.9758)\n",
      "Epoch: [39/50]\tIter: [67/83]\tTime 0.062 (0.114)\tLoss 0.0214 (0.0251)\tIOU 0.9552 (0.9536)\tDICE 0.9766 (0.9758)\n",
      "Test\tIter: [1/17]\tTime 3.611 (3.611)\tLoss 0.0159 (0.0159)\tIOU 0.9812 (0.9812)\tDICE 0.9904 (0.9904)\n",
      "New best dice: 0.9776\n",
      "Epoch: [40/50]\tIter: [1/83]\tTime 3.420 (3.420)\tLoss 0.0223 (0.0223)\tIOU 0.9560 (0.9560)\tDICE 0.9771 (0.9771)\n",
      "Epoch: [40/50]\tIter: [65/83]\tTime 0.064 (0.115)\tLoss 0.0286 (0.0244)\tIOU 0.9470 (0.9544)\tDICE 0.9722 (0.9762)\n",
      "Epoch: [40/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0204 (0.0248)\tIOU 0.9617 (0.9537)\tDICE 0.9802 (0.9759)\n",
      "Test\tIter: [1/17]\tTime 3.572 (3.572)\tLoss 0.0189 (0.0189)\tIOU 0.9821 (0.9821)\tDICE 0.9908 (0.9908)\n",
      "Current best dice: 0.9776\n",
      "Epoch: [41/50]\tIter: [1/83]\tTime 3.359 (3.359)\tLoss 0.0250 (0.0250)\tIOU 0.9530 (0.9530)\tDICE 0.9755 (0.9755)\n",
      "Epoch: [41/50]\tIter: [67/83]\tTime 0.062 (0.113)\tLoss 0.0247 (0.0241)\tIOU 0.9536 (0.9545)\tDICE 0.9758 (0.9763)\n",
      "Epoch: [41/50]\tIter: [83/83]\tTime 0.050 (0.103)\tLoss 0.0236 (0.0240)\tIOU 0.9595 (0.9547)\tDICE 0.9790 (0.9764)\n",
      "Test\tIter: [1/17]\tTime 3.609 (3.609)\tLoss 0.0149 (0.0149)\tIOU 0.9827 (0.9827)\tDICE 0.9912 (0.9912)\n",
      "Current best dice: 0.9776\n",
      "Epoch: [42/50]\tIter: [1/83]\tTime 3.399 (3.399)\tLoss 0.0199 (0.0199)\tIOU 0.9585 (0.9585)\tDICE 0.9784 (0.9784)\n",
      "Epoch: [42/50]\tIter: [31/83]\tTime 0.067 (0.171)\tLoss 0.0252 (0.0238)\tIOU 0.9534 (0.9546)\tDICE 0.9757 (0.9763)\n",
      "Epoch: [42/50]\tIter: [69/83]\tTime 0.060 (0.112)\tLoss 0.0190 (0.0234)\tIOU 0.9611 (0.9552)\tDICE 0.9798 (0.9766)\n",
      "Test\tIter: [1/17]\tTime 3.527 (3.527)\tLoss 0.0133 (0.0133)\tIOU 0.9872 (0.9872)\tDICE 0.9935 (0.9935)\n",
      "New best dice: 0.9781\n",
      "Epoch: [43/50]\tIter: [1/83]\tTime 3.466 (3.466)\tLoss 0.0247 (0.0247)\tIOU 0.9536 (0.9536)\tDICE 0.9758 (0.9758)\n",
      "Epoch: [43/50]\tIter: [33/83]\tTime 0.063 (0.167)\tLoss 0.0242 (0.0229)\tIOU 0.9538 (0.9555)\tDICE 0.9759 (0.9768)\n",
      "Epoch: [43/50]\tIter: [67/83]\tTime 0.061 (0.115)\tLoss 0.0224 (0.0231)\tIOU 0.9574 (0.9554)\tDICE 0.9779 (0.9768)\n",
      "Test\tIter: [1/17]\tTime 3.594 (3.594)\tLoss 0.0137 (0.0137)\tIOU 0.9890 (0.9890)\tDICE 0.9944 (0.9944)\n",
      "Current best dice: 0.9781\n",
      "Epoch: [44/50]\tIter: [1/83]\tTime 3.456 (3.456)\tLoss 0.0241 (0.0241)\tIOU 0.9536 (0.9536)\tDICE 0.9758 (0.9758)\n",
      "Epoch: [44/50]\tIter: [33/83]\tTime 0.064 (0.166)\tLoss 0.0178 (0.0228)\tIOU 0.9632 (0.9556)\tDICE 0.9809 (0.9769)\n",
      "Test\tIter: [1/17]\tTime 3.588 (3.588)\tLoss 0.0177 (0.0177)\tIOU 0.9741 (0.9741)\tDICE 0.9867 (0.9867)\n",
      "Current best dice: 0.9781\n",
      "Epoch: [45/50]\tIter: [1/83]\tTime 3.381 (3.381)\tLoss 0.0268 (0.0268)\tIOU 0.9519 (0.9519)\tDICE 0.9749 (0.9749)\n",
      "Epoch: [45/50]\tIter: [33/83]\tTime 0.064 (0.165)\tLoss 0.0190 (0.0239)\tIOU 0.9600 (0.9538)\tDICE 0.9792 (0.9759)\n",
      "Epoch: [45/50]\tIter: [65/83]\tTime 0.063 (0.115)\tLoss 0.0237 (0.0234)\tIOU 0.9532 (0.9543)\tDICE 0.9756 (0.9762)\n",
      "Epoch: [45/50]\tIter: [83/83]\tTime 0.049 (0.104)\tLoss 0.0281 (0.0232)\tIOU 0.9498 (0.9547)\tDICE 0.9738 (0.9764)\n",
      "Test\tIter: [1/17]\tTime 3.660 (3.660)\tLoss 0.0115 (0.0115)\tIOU 0.9895 (0.9895)\tDICE 0.9947 (0.9947)\n",
      "New best dice: 0.9786\n",
      "Epoch: [46/50]\tIter: [1/83]\tTime 3.439 (3.439)\tLoss 0.0204 (0.0204)\tIOU 0.9576 (0.9576)\tDICE 0.9779 (0.9779)\n",
      "Epoch: [46/50]\tIter: [63/83]\tTime 0.065 (0.117)\tLoss 0.0219 (0.0214)\tIOU 0.9567 (0.9572)\tDICE 0.9775 (0.9777)\n",
      "Test\tIter: [1/17]\tTime 3.609 (3.609)\tLoss 0.0124 (0.0124)\tIOU 0.9886 (0.9886)\tDICE 0.9942 (0.9942)\n",
      "Current best dice: 0.9786\n",
      "Epoch: [47/50]\tIter: [1/83]\tTime 3.430 (3.430)\tLoss 0.0227 (0.0227)\tIOU 0.9540 (0.9540)\tDICE 0.9760 (0.9760)\n",
      "Epoch: [47/50]\tIter: [34/83]\tTime 0.062 (0.163)\tLoss 0.0210 (0.0217)\tIOU 0.9594 (0.9568)\tDICE 0.9789 (0.9776)\n",
      "Epoch: [47/50]\tIter: [67/83]\tTime 0.062 (0.113)\tLoss 0.0232 (0.0216)\tIOU 0.9540 (0.9568)\tDICE 0.9760 (0.9775)\n",
      "Test\tIter: [1/17]\tTime 3.672 (3.672)\tLoss 0.0168 (0.0168)\tIOU 0.9776 (0.9776)\tDICE 0.9885 (0.9885)\n",
      "Current best dice: 0.9786\n",
      "Epoch: [48/50]\tIter: [1/83]\tTime 3.703 (3.703)\tLoss 0.0197 (0.0197)\tIOU 0.9603 (0.9603)\tDICE 0.9794 (0.9794)\n",
      "Epoch: [48/50]\tIter: [33/83]\tTime 0.063 (0.175)\tLoss 0.0194 (0.0216)\tIOU 0.9593 (0.9565)\tDICE 0.9789 (0.9774)\n",
      "Test\tIter: [1/17]\tTime 3.877 (3.877)\tLoss 0.0115 (0.0115)\tIOU 0.9890 (0.9890)\tDICE 0.9944 (0.9944)\n",
      "New best dice: 0.9787\n",
      "Epoch: [49/50]\tIter: [1/83]\tTime 3.688 (3.688)\tLoss 0.0202 (0.0202)\tIOU 0.9585 (0.9585)\tDICE 0.9785 (0.9785)\n",
      "Epoch: [49/50]\tIter: [33/83]\tTime 0.063 (0.174)\tLoss 0.0233 (0.0211)\tIOU 0.9545 (0.9573)\tDICE 0.9763 (0.9778)\n",
      "Epoch: [49/50]\tIter: [65/83]\tTime 0.063 (0.119)\tLoss 0.0275 (0.0219)\tIOU 0.9496 (0.9561)\tDICE 0.9737 (0.9772)\n",
      "Epoch: [49/50]\tIter: [67/83]\tTime 0.061 (0.117)\tLoss 0.0225 (0.0220)\tIOU 0.9533 (0.9561)\tDICE 0.9756 (0.9771)\n",
      "Test\tIter: [1/17]\tTime 3.519 (3.519)\tLoss 0.0162 (0.0162)\tIOU 0.9781 (0.9781)\tDICE 0.9887 (0.9887)\n",
      "Current best dice: 0.9787\n",
      "Epoch: [50/50]\tIter: [1/83]\tTime 3.473 (3.473)\tLoss 0.0226 (0.0226)\tIOU 0.9547 (0.9547)\tDICE 0.9764 (0.9764)\n",
      "Epoch: [50/50]\tIter: [65/83]\tTime 0.063 (0.115)\tLoss 0.0241 (0.0215)\tIOU 0.9515 (0.9564)\tDICE 0.9747 (0.9773)\n",
      "Test\tIter: [1/17]\tTime 3.553 (3.553)\tLoss 0.0106 (0.0106)\tIOU 0.9894 (0.9894)\tDICE 0.9946 (0.9946)\n",
      "Current best dice: 0.9787\n",
      "best dice:  tensor(0.9787, device='cuda:0')\n",
      "716.6742668\n",
      "Done!\n",
      "C:\\Users\\admin\\Desktop\\cnn-facies-classifier-master\\tmp\\voxel\\Conv2_5D_330samples\\canal_2\\model.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2506: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 64, 32, 32, 32]             640\n",
      "       BatchNorm3d-2       [-1, 64, 32, 32, 32]             128\n",
      "              ReLU-3       [-1, 64, 32, 32, 32]               0\n",
      "            Conv3d-4       [-1, 64, 32, 32, 32]          36,928\n",
      "       BatchNorm3d-5       [-1, 64, 32, 32, 32]             128\n",
      "              ReLU-6       [-1, 64, 32, 32, 32]               0\n",
      "         MaxPool3d-7       [-1, 64, 16, 16, 16]               0\n",
      "     _EncoderBlock-8       [-1, 64, 16, 16, 16]               0\n",
      "            Conv3d-9      [-1, 128, 16, 16, 16]          73,856\n",
      "      BatchNorm3d-10      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-11      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-12      [-1, 128, 16, 16, 16]         147,584\n",
      "      BatchNorm3d-13      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-14      [-1, 128, 16, 16, 16]               0\n",
      "        MaxPool3d-15         [-1, 128, 8, 8, 8]               0\n",
      "    _EncoderBlock-16         [-1, 128, 8, 8, 8]               0\n",
      "         Upsample-17      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-18       [-1, 64, 16, 16, 16]         110,656\n",
      "      BatchNorm3d-19       [-1, 64, 16, 16, 16]             128\n",
      "             ReLU-20       [-1, 64, 16, 16, 16]               0\n",
      "           Conv3d-21       [-1, 32, 16, 16, 16]          18,464\n",
      "      BatchNorm3d-22       [-1, 32, 16, 16, 16]              64\n",
      "             ReLU-23       [-1, 32, 16, 16, 16]               0\n",
      "    _DecoderBlock-24       [-1, 32, 16, 16, 16]               0\n",
      "         Upsample-25       [-1, 32, 32, 32, 32]               0\n",
      "           Conv3d-26        [-1, 4, 32, 32, 32]             132\n",
      "================================================================\n",
      "Total params: 389,220\n",
      "Trainable params: 389,220\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 148.00\n",
      "Params size (MB): 1.48\n",
      "Estimated Total Size (MB): 149.61\n",
      "----------------------------------------------------------------\n",
      "Precision: \t0.925094336606808\n",
      "Recall: \t0.9213953299115795\n",
      "F1-Score: \t0.9203747714216014\n",
      "IOU: \t0.8642402690819369\n",
      "elapsed:  \t 80.09883690000004\n"
     ]
    }
   ],
   "source": [
    "# encoding: utf-8\n",
    "#POC 2,5D unet pre trained\n",
    "\n",
    "\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "import fire\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from poc_dataset_ACS import BaseDatasetVoxel\n",
    "from mylib.loss import soft_cross_entropy_loss\n",
    "from mylib.utils import MultiAverageMeter, save_model, log_results, to_var, set_seed, \\\n",
    "        to_device, initialize, categorical_to_one_hot, copy_file_backup, redirect_stdout\n",
    "from poc_config_2dpre import POCVoxelConfig as cfg\n",
    "from poc_config_2dpre import POCVoxelEnv as env\n",
    "\n",
    "from unet import UNet\n",
    "from acsconv.models import ACSUNet\n",
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "\n",
    "from mylib.metrics import cal_batch_iou, cal_batch_dice, AUROC_per_case\n",
    "from mylib.loss import soft_dice_loss\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "canal =2\n",
    "def main(save_path=cfg.save, \n",
    "         n_epochs=cfg.n_epochs, \n",
    "         seed=cfg.seed\n",
    "         ):\n",
    "    if seed is not None:\n",
    "        set_seed(cfg.seed)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "    # # Models\n",
    "    os.makedirs(save_path,exist_ok = True)\n",
    "    #copy_file_backup(save_path)\n",
    "    redirect_stdout(save_path)\n",
    "\n",
    "    # Datasets\n",
    "    train_data = env.data_train\n",
    "    test_data = env.data_train\n",
    "    shape_cp = env.shape_checkpoint\n",
    "    #val_data=env.data_test\n",
    "\n",
    "\n",
    "\n",
    "    train_set = BaseDatasetVoxel(train_data, cfg.train_samples)\n",
    "    valid_set = None\n",
    "    test_set = BaseDatasetVoxel(test_data, cfg.train_samples)\n",
    "\n",
    "    model = groupmodel[canal]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(model)\n",
    "    torch.save(model.state_dict(), os.path.join(save_path, format(canal)+ 'model.dat'))\n",
    "    # Train the model\n",
    "    train(model=model, train_set=train_set, valid_set=valid_set, test_set=test_set, save=save_path, n_epochs=n_epochs)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "    print('Done!')\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train_set, test_set, save, valid_set, n_epochs):\n",
    "\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_set, batch_size=cfg.train_batch_size, shuffle=True,\n",
    "                                pin_memory=(torch.cuda.is_available()), num_workers=cfg.num_workers)\n",
    "    test_loader = DataLoader(test_set, batch_size=cfg.test_batch_size, shuffle=False,\n",
    "                                pin_memory=(torch.cuda.is_available()), num_workers=cfg.num_workers)\n",
    "    if valid_set is None:\n",
    "        valid_loader = None\n",
    "    else:\n",
    "        valid_loader = DataLoader(valid_set, batch_size=cfg.batch_size, shuffle=False,\n",
    "                                pin_memory=(torch.cuda.is_available()), num_workers=cfg.num_workers)\n",
    "    # Model on cuda\n",
    "    model = to_device(model)\n",
    "\n",
    "    # Wrap model for multi-GPUs, if necessary\n",
    "    model_wrapper = model\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model_wrapper = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model_wrapper.parameters(), lr=cfg.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=cfg.milestones,\n",
    "                                                     gamma=cfg.gamma)\n",
    "\n",
    "    # Start log\n",
    "    logs = ['loss', 'iou', 'dice'] + ['iou{}'.format(i) for i in range(4)]+['dice{}'.format(i) for i in range(4)]\n",
    "    train_logs = ['train_'+log for log in logs]\n",
    "    test_logs = ['test_'+log for log in logs]\n",
    "    log_dict = OrderedDict.fromkeys(train_logs+test_logs, 0)\n",
    "    with open(os.path.join(save, 'logs.csv'), 'w') as f:\n",
    "        f.write('epoch,')\n",
    "        for key in log_dict.keys():\n",
    "            f.write(key+',')\n",
    "        f.write('\\n')\n",
    "    writer = SummaryWriter(log_dir=os.path.join(save, 'Tensorboard_Results'))\n",
    "\n",
    "    # Train model\n",
    "    best_dice = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        os.makedirs(os.path.join(cfg.save, 'canal_{}'.format(canal)),exist_ok = True)\n",
    "        train_meters = train_epoch(\n",
    "            model=model_wrapper,\n",
    "            loader=train_loader,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch,\n",
    "            n_epochs=n_epochs,\n",
    "            writer=writer\n",
    "        )\n",
    "        # if (epoch+1)%5==0:\n",
    "        test_meters = test_epoch(\n",
    "            model=model_wrapper,\n",
    "            loader=test_loader,\n",
    "            epoch=epoch,\n",
    "            is_test=True,\n",
    "            writer = writer\n",
    "        )\n",
    "        scheduler.step()\n",
    "\n",
    "        # Log results\n",
    "        for i, key in enumerate(train_logs):\n",
    "            log_dict[key] = train_meters[i]\n",
    "        for i, key in enumerate(test_logs):\n",
    "            log_dict[key] = test_meters[i]\n",
    "\n",
    "        log_results(save, epoch, log_dict, writer=writer)\n",
    "\n",
    "        if cfg.save_all:\n",
    "            torch.save(model.state_dict(), os.path.join(save, 'canal_{}'.format(canal), 'model.dat'))\n",
    "\n",
    "        if log_dict['test_dice'] > best_dice:\n",
    "            torch.save(model.state_dict(), os.path.join(save,'canal_{}'.format(canal), 'model.dat'))\n",
    "            best_dice = log_dict['test_dice']\n",
    "            print('New best dice: %.4f' % log_dict['test_dice'])\n",
    "            #print(2.*intersection/union)\n",
    "        else:\n",
    "            print('Current best dice: %.4f' % best_dice)\n",
    "            #print(2.*intersection/union)\n",
    "    writer.close()\n",
    "\n",
    "    with open(os.path.join(save, 'logs.csv'), 'a') as f:\n",
    "        f.write(',,,,best dice,%0.5f\\n' % (best_dice))\n",
    "    # Final test of the best model on test set\n",
    "    print('best dice: ', best_dice)\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "def train_epoch(model, loader, optimizer, epoch, n_epochs, print_freq=1, writer=None):\n",
    "    meters = MultiAverageMeter()\n",
    "    # Model on train mode\n",
    "    model.train()\n",
    "    global iteration\n",
    "    end = time.time()\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        # Create vaiables\n",
    "        x = to_var(x)\n",
    "        y = to_var(y)\n",
    "        # compute output\n",
    "        pred_logit = model(x)\n",
    "        loss = soft_dice_loss(pred_logit, y, smooth=1e-2)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y = y.long()\n",
    "        \n",
    "        batch_size = y.size(0)\n",
    "        iou = cal_batch_iou(pred_logit, y)\n",
    "        dice = cal_batch_dice(pred_logit, y)\n",
    "\n",
    "        logs = [loss.item(), iou[1:].mean(), dice[1:].mean()]+ \\\n",
    "                            [iou[i].item() for i in range(len(iou))]+ \\\n",
    "                            [dice[i].item() for i in range(len(dice))]+ \\\n",
    "                            [time.time() - end]\n",
    "        meters.update(logs, batch_size)   \n",
    "        writer.add_scalar('train_loss_logs', loss.item(), iteration)\n",
    "        with open(os.path.join(cfg.save, 'loss_logs.csv'), 'a') as f:\n",
    "            f.write('%09d,%0.6f,\\n'%((iteration + 1),loss.item(),))\n",
    "        iteration += 1\n",
    "\n",
    "\n",
    "        # measure elapsed time\n",
    "        end = time.time()\n",
    "        # print stats\n",
    "        print_freq = 2 // meters.val[-1] + 1\n",
    "        if batch_idx % print_freq == 0:\n",
    "            res = '\\t'.join([\n",
    "                'Epoch: [%d/%d]' % (epoch + 1, n_epochs),\n",
    "                'Iter: [%d/%d]' % (batch_idx + 1, len(loader)),\n",
    "                'Time %.3f (%.3f)' % (meters.val[-1], meters.avg[-1]),\n",
    "                'Loss %.4f (%.4f)' % (meters.val[0], meters.avg[0]),\n",
    "                'IOU %.4f (%.4f)' % (meters.val[1], meters.avg[1]),\n",
    "                'DICE %.4f (%.4f)' % (meters.val[2], meters.avg[2]),\n",
    "            ])\n",
    "            print(res)\n",
    "\n",
    "    return meters.avg[:-1] #intersection, union\n",
    "\n",
    "\n",
    "def test_epoch(model, loader, epoch, print_freq=1, is_test=True, writer=None):\n",
    "    meters = MultiAverageMeter()\n",
    "    # Model on eval mode\n",
    "    model.eval()\n",
    "    gt_classes = []\n",
    "    pred_all_probs = []\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(loader):\n",
    "            \n",
    "            x = to_var(x)\n",
    "            \n",
    "            \n",
    "            y = to_var(y)\n",
    "            \n",
    "            pred_logit = model(x)\n",
    "            \n",
    "            # calculate metrics\n",
    "            pred_class = pred_logit.max(dim=1)[1]\n",
    "            pred_probs = pred_logit.softmax(-1)\n",
    "            pred_all_probs.append(pred_probs.cpu())\n",
    "            gt_classes.append(y.cpu())\n",
    "            \n",
    "            #print(gt_classes.shape) #pred_class[20,48,48,48]\n",
    "            #print(pred_probs[1]) #y e pred_probs[20,6,48,48,48]\n",
    "            \n",
    "            batch_size, n_classes = pred_logit.shape[:2]\n",
    "            \n",
    "\n",
    "            loss = soft_dice_loss(pred_logit, y, smooth=1e-2)\n",
    "            y = y.long()\n",
    "            batch_size = y.size(0)\n",
    "            iou = cal_batch_iou(pred_logit, y)\n",
    "            dice = cal_batch_dice(pred_logit, y)\n",
    " \n",
    "            logs = [loss.item(), iou[1:].mean(), dice[1:].mean()]+ \\\n",
    "                                [iou[i].item() for i in range(len(iou))]+ \\\n",
    "                                [dice[i].item() for i in range(len(dice))]+ \\\n",
    "                                [time.time() - end]\n",
    "            meters.update(logs, batch_size)\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "            print_freq = 2 // meters.val[-1] + 1\n",
    "            if batch_idx % print_freq == 0:\n",
    "                res = '\\t'.join([\n",
    "                    'Test' if is_test else 'Valid',\n",
    "                    'Iter: [%d/%d]' % (batch_idx + 1, len(loader)),\n",
    "                    'Time %.3f (%.3f)' % (meters.val[-1], meters.avg[-1]),\n",
    "                    'Loss %.4f (%.4f)' % (meters.val[0], meters.avg[0]),\n",
    "                    'IOU %.4f (%.4f)' % (meters.val[1], meters.avg[1]),\n",
    "                    'DICE %.4f (%.4f)' % (meters.val[2], meters.avg[2]),\n",
    "                ])\n",
    "                print(res)\n",
    "\n",
    "    return meters.avg[:-1]\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #fire.Fire(main)\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x213b9294c08>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAEYCAYAAAAkpo9KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3hU1daH35WEXhNQIQldSgg9AaSDonRsKNgQbLeIXe+1o1ixYr1+NlAsNEGqgg0VG02pFoIEIQEpKiglmGF9f+yTMOkTSGYGWC/PeTJnn3X2+c1wZs3ae6+9j6gqhmEYBkSEWoBhGEa4YA7RMAzDwxyiYRiGhzlEwzAMD3OIhmEYHuYQDcMwPMwhGkeMiFQQkdkisktEph5BPReJyIKS1BYqRKSbiPwYah1G8RDLQzx+EJELgRuBZsCfwHfAA6q66AjrvQS4BuisqplHLDTMEREFGqtqSqi1GCWLRYjHCSJyIzAOeBA4CagLPA+cWQLV1wN+Oh6cYSCISFSoNRiHiaradoxvQDXgL+C8QmzK4RxmureNA8p5x3oCm4GbgG3AFmCkd+xe4ADwt3eNy4F7gDf86q4PKBDl7Y8AfsZFqRuAi/zKF/md1xlYAuzy/nb2O7YQuA/4wqtnAVCzgPeWpf8/fvrPAvoDPwG/Abf72XcAvgL+8GyfBcp6xz7z3sse7/0O9av/v8BWYGJWmXdOI+8a7bz9WGAH0DPU94ZtOTeLEI8POgHlgRmF2NwBnAK0AVrjnMKdfsdr4RxrHM7pPSci0ao6Ghd1TlbVyqr6SmFCRKQS8DTQT1Wr4Jzed/nYxQBzPdsawBPAXBGp4Wd2ITASOBEoC9xcyKVr4T6DOOBu4CXgYiAJ6AbcLSINPVsfcANQE/fZnQb8G0BVu3s2rb33O9mv/hhctHyV/4VVdT3OWb4pIhWB8cAEVV1YiF4jBJhDPD6oAezQwpu0FwFjVHWbqm7HRX6X+B3/2zv+t6rOw0VHTQ9Tz0GghYhUUNUtqromH5sBwDpVnaiqmar6NvADMMjPZryq/qSq+4ApOGdeEH/j+kv/BibhnN1Tqvqnd/01QCsAVV2mql97100F/g/oEcB7Gq2qGZ6eHKjqS8A64BugNu4HyAgzzCEeH+wEahbRtxULbPTb3+iVZdeRy6HuBSoXV4iq7sE1M/8JbBGRuSLSLAA9WZri/Pa3FkPPTlX1ea+zHNavfsf3ZZ0vIk1EZI6IbBWR3bgIuGYhdQNsV9X9Rdi8BLQAnlHVjCJsjRBgDvH44CtgP67frCDScc29LOp6ZYfDHqCi334t/4OqOl9VT8dFSj/gHEVRerI0pR2mpuLwP5yuxqpaFbgdkCLOKTRdQ0Qq4/plXwHu8boEjDDDHOJxgKruwvWbPSciZ4lIRREpIyL9ROQRz+xt4E4ROUFEanr2bxzmJb8DuotIXRGpBtyWdUBEThKRwV5fYgau6e3Lp455QBMRuVBEokRkKNAcmHOYmopDFWA38JcXvf4r1/FfgYZ5ziqcp4BlqnoFrm/0hSNWaZQ45hCPE1T1CVwO4p3AdmATMAp41zO5H1gKrARWAcu9ssO51gfAZK+uZeR0YhG40ep03MhrD7wBi1x17AQGerY7cSPEA1V1x+FoKiY34wZs/sRFr5NzHb8HeE1E/hCR84uqTETOBPriugnA/T+0E5GLSkyxUSJYYrZhGIaHRYiGYRge5hANwzA8zCEahmF4mEM0DMPwsEnoR4hEVVApWyXUMopN24S6oZZw3HE0D19+u3zZDlU9oSTqiqxaTzUzz2SeHOi+7fNVtW9JXK84mEM8QqRsFco1LTLzIuz44ptnQy3huONozuioWDYi96yhw0Yz9xX5ndn/3XNFzQwqFcwhGoYRXEQgIjLUKvLFHKJhGMFHwnP4whyiYRjBR4qaGh4azCEahhFkrMlsGIbhEKzJbBiG4bAI0TAM4xDWh2gYhgEg1mQ2DMMAXB+iNZkNwzDAIkTDMAx/IqwP0TAMw5rMhmEYh7Ams2EYxiEsQjQMw8DlIFoeomEYhoc1mQ3DMCCcp+6Fp5s+xjm9cwIrZtzF6pmjuXnk6XmO160dzbwXrmHx5NuY/9J1xJ1YPfvY/deeydKpt7N06u0MOaNdMGUDsGD++7RKbEpis5N59JGH8xzPyMjg4guHktjsZLp17sjG1NTsY4+OfYjEZifTKrEpHyyYH0TVjqNV+4L579M6sRktEhrzWAG6L7lwGC0SGtO9yynZunfu3Enf00/lhOgq3HDdqKBqLpKsZnNBW4goNYcoIj4R+c5vqy8iPUVkTgnVnyoihS4zLiILRSS5CJuXRaR5SWgKhIgIYdyt53PmqOdpe+79nNc3iWYNa+WweeiGs3lz7mI6DH2IB198jzHXDAagb9dE2iTUoeOwh+l+yWNcf2lvqlQqHyzp+Hw+rr/2ambOfo9vV65l6qS3+X7t2hw2E159hejq0az5IYVrrruBO27/LwDfr13L1MmTWL5iDbPmvM911/wbn89n2gPQfcN1o3h39jyWr1jD1MmT8uoe/wrVo6uz+vt1XHPt9dx5+60AlC9fnrvvGcODYx8NitaAyVrtprAtRJTmlfepahu/LbUUr3XYqOoVqrq2aMuSoX2L+qzftIPUtJ38nelj6vzlDOzZKodNs4a1WfjNjwB8uuQnBvZsCUBCw1p8vmwdPt9B9u4/wKqfNnNG54RgSWfJ4sU0anQyDRo2pGzZspw3dBhzZs/MYTNn9kwuuuRSAM45dwgLP/4IVWXO7JmcN3QY5cqVo36DBjRqdDJLFi827UWwdElO3UPOH5pH99zZs7jY0332uUNY+InTXalSJTp36Ur58sH70QwMr8lc2BYiQuaKRSRGRN4VkZUi8rWItCqivIaILBCRb0Xk/3C/M3iR5w8i8pp3zjQRqZjP9f4nIktFZI2I3OtXnh1FishfIvKAiKzwrn1SSb/v2BOrsfnX37P30379nbgTquWwWfVTGmed1gaAM09tTdXKFYipVomVP6XRp0tzKpQvQ43qleiR3IT4WtElLbFA0tPTiI+vk70fFxdPWlpaXps6ziYqKoqq1aqxc+dO0tLynpuenvPc0uRo1Z6elkZcfHyh13Y2eXWHNcdhhFjBr7k8I5/j9wLfqmor4Hbg9SLKRwOLVLUtMAvwf45mU+BF75zdwL/zud4dqpoMtAJ6ZDnaXFQCvlbV1sBnwJXFeL8BIeTtH8n9LLbbnpxBt6ST+ert/9It6WTSfv2dTJ+Pj77+gfcXreWTCTfx2kMj+WblBjIzD5a0xALJ76lxkqu/p0CbAM4tTY5W7UekO1yR4zNC9G8yn53P8a7ARABV/RioISLVCinvDrzhlc8Ffvera5OqfuG9fsOrIzfni8hy4FsgEciv3/AAkNXHuQyon98bE5GrvGhzaVHPl81N2rY/iD/pUFQXd1I06dt35bDZsn0Xw25+mU4XjGX0s7MB2P3XfgAeeWU+pwx7mIH/ehYRIWXTtmJd/0iIi4tn8+ZN2ftpaZuJjY3Na7PJ2WRmZrJ71y5iYmKIi897bu3aOc8tTY5W7XHx8aRt3lzotZ1NXt1hzfE2qBIA+b1rLaTc/29Bx/PdF5EGwM3AaV4UORfIr2Plbz30c+ujgLQkVX1RVZNVNVmiKhQgKX+WrtnIyXVPoF5sDcpERXJen3bMXbgyh02N6pWyf+FvuawPr838GnADMjHVKgHQonEsLRrH8uFXPxTr+kdCcvv2pKSsI3XDBg4cOMDUyZMYMHBwDpsBAwfz5sTXAJj+zjR69DoVEWHAwMFMnTyJjIwMUjdsICVlHe07dDDtRZCUnFP3tCmT8+juP3AQb3i6Z7wzjR49Tw3vCBEXwRa2hYpQ5iF+BlwE3CciPYEdqrpbRIoqv19E+gH+nWd1RaSTqn4FXAAsynWtqsAeYJfXL9gPWFh6b61gfL6D3DB2CrOfv5rICOG1mV/z/c9buetfA1i+9hfmfrqK7smNGXPNYFRh0fIUrn9oCgBloiL58NXrAfjzr/1cdsdr+HzBazJHRUXx5FPPMmhAH3w+H5eOuIzmiYmMuedu2iUlM3DQYEZcdjmXjbiExGYnEx0dw8Q3JwHQPDGRc887n7atmhMVFcW4p58jMjJ4TaOjVXtUVBRPjHuGwQP64jvoY/ilI/PqHnk5l48YTouExkRHx/D6G29nn9+scQP+3L2bAwcOMHvWTGbPnU9C86AlVeSLCEiYrnYj+fU/lEjFIn+pauVcZT2Bm1V1oIjEAOOBBsBe4CpVXVlIeQ3gbaAm8ClwDpAEVAbm4RxsZ2AdcImq7hWRhd71lorIBKAj8DOQAcxS1Qm5bLI1i8gQYKCqjijsfUZUPFHLNT3/SD6qkPD7kmdDLeG4o7S+a8GgYtmIZV4f/BETGdNAK/QeXajNnqkjS+x6xaHUIsTcztArW4gXmanqb8CZ+dgUVL4TOMOv6AYAEakMHFTVf+ZzTk+/1yMK0OlvU9nv9TRgWn7nGIZxZEREhOecEJu6ZxhG0AnXPs6j3iF6Cd8tQq3DMIwAEfIfOg0DjnqHaBjG0YUg1mQ2DMPIIlybzOHppg3DOKYpiTxEEekrIj+KSIqI3JrP8boi8ok33XeliPQvqk5ziIZhBBcvD7GwrcgqRCKB53A5xc2BC/JZtepOYIo33XcY8HxR9ZpDNAwjqAiFR4cBRogdgBRV/VlVDwCTyJuup7hJGQDVgPSiKrU+RMMwgk4AUWBNEVnqt/+iqr7otx8HbPLb34ybeOHPPcACEbkGt3BL76Iuag7RMIzgIgENquwoYqZKYWseZHEBMEFVHxeRTsBEEWmhqgXOdzWHaBhG0CmBUebNQB2//XjyNokvB/oCqOpXIlIeN/W3wCWirA/RMIygkpWHWNgWAEuAxiLSQETK4gZNZuWy+QU4DUBEEnArXG0vrFJziIZhBB8pYisCVc0ERgHzge9xo8lrRGSMiGStj3YTcKWIrMAtDDNCi1hhw5rMhmEEl8D6EItEVefhVrryL7vb7/VaoEtx6jSHaBhG0LGpe4ZhGFmE58w9c4iGYQQXEVvcwTAMI5twXdzBHOIR0iahLl98/UyoZRSb6DMeDLWEw2bbvDzz+I8KMg8evY8QKGnMIRqGYXiE60OmzCEahhFcSijtpjQwh2gYRlARQvos+kIxh2gYRpARIqzJbBiG4bAms2EYBq65HBlpDtEwDAOwPkTDMIxsrMlsGIaBiw5tUMUwDAOAwB81GmzMIRqGEXTC1B+aQzQMI8hYk9kwDMPhZqqYQzQMwwAsQjQMw8gmTANEc4iGYQQZW+3GMAzDIba4g2EYxiHCNEA0h2gYRvAJ1yZzeD766jhgwfz3aZ3YjBYJjXnskYfzHM/IyOCSC4fRIqEx3bucwsbU1Oxjj459iBYJjWmd2IwPFswPomo4vX1DVrz2D1ZP/Cc3X9Apz/G6J1Vl3mMXsvilK5j/xEXE1awCQKtGJ7LwmeEse/VKFr90BUN6JgRVN8AHC96nXasEWic24YlHx+Y5npGRwYiLh9E6sQm9unVi48ZUAJYuWUyXju3o0rEdnTu0ZfbMGUHV/eGC9+nQpjlJLZsy7rH8dV82/AKSWjald49O/OLp/mVjKrE1KtP9lCS6n5LEjdf+O6i6CyJr6l5hW6gIeYQoIj5glafle+BSVd1biP2Xqtq5iDqvB17MqkdE/lLVyiUo+4jw+XzccN0o5sxbQFx8PN06dWDAwMEkNG+ebTNh/CtUj67O6u/XMXXyJO68/VYmvjWJ79euZdqUySz7bjVb0tMZ0O90Vq75kcjIyFLXHREhjLuuDwNueZu07btZ9L+RzPlyHT9s3JFt89A/T+PNBat4c8EqerStx5gre3L5Q7PZm5HJ5Q/PZn3a79SuUZkvXriMD5b8zK49GaWuG9xnftP11zBz7nzi4uLp2bUj/QcOolnCoc/89QmvUj06mhVrfmLalEmMvuNWJrwxieaJLfj0i8VERUWxdcsWOndsS78Bg4iKKv2vj8/n4z83Xsv02e8TGxfPad1Ooe+AnLrfeO1VqlePZtmqH3ln6mTuues2Xn39bQDqN2jEZ18vK3WdxcUixILZp6ptVLUFcAD4Z2HGRTlDj+uBiiUhTkRK/K5fumQxjRqdTIOGDSlbtixDzh/KnNkzc9jMnT2Liy+5FICzzx3Cwk8+QlWZM3smQ84fSrly5ajfoAGNGp3M0iWLS1pivrRvFsv6tN9J3fIHf2ceZOrHaxnYuXEOm2b1arJweSoAn367kYGdmwCQsvk31qf9DsCWnX+x/Y891KxeIv9FAbF0yWIaNmpEgwbuMz/3vKHMnTMrh83cOTO54KLhAJx1zhAWLvwYVaVixYrZzm9/xv6gfpmXLV1Mg4aNqO/pPmfI+byXS/e8ObMYdtElAJx59rl85ukOZ8I1QgwHh+jP58DJACJyo4is9rbrswxE5C/vb08RWSgi00TkBxF5UxzXArHAJyLyid95j4vIchH5SERO8MquFJElIrJCRN4RkYpe+QQRecI7P28b5QhJT0sjLj4+ez8uLp709LR8bOoAEBUVRdVq1di5cyfp6WnEe+UAsXFxpKflPLe0iK1Zhc3bdmfvp+34k7gTquSwWbV+G2d1bwbAmd2aUrVSOWKqVshhk9ysNmWjIvk5/ffSF+2xJYDPbUt6erZNVFQUVatW47edOwFYsvgbOrRrSafk1ox7+vmgRIdZmuJy6I5ny5b0Am1y6/5l4wZ6dEpmYJ9efPXF50HRXCTims2FbaGiQIcoIlUL20paiBeJ9QNWiUgSMBLoCJwCXCkibfM5rS0uGmwONAS6qOrTQDrQS1V7eXaVgOWq2g74FBjtlU9X1faq2hrXXL/cr+4mQG9VvSkfrVeJyFIRWbpjx/Ziv9f8fr1zRx0F2QRybmmR32Vyy7nthY/o1rouX/3fZXRrVZe07bvJ9B3MPl4rphKv3DaYfzwyJ8+5pcnhfuZZb7p9h44sXr6KhYu+4fFHx7J///5S0ZmbgHSTv81JtWqz8ocNfPrVUu5/+DGuHHkJu3fvzmMbbMRb7aawLVQUFiGuAVZ7f9fk2l9dghoqiMh3wFLgF+AVoCswQ1X3qOpfwHSgWz7nLlbVzap6EPgOqF/ANQ4Ck73Xb3j1A7QQkc9FZBVwEZDod85UVfXlV5mqvqiqyaqaXLPmCQG/0Szi4uNJ27w5ez8tbTO1a8fmY7MJgMzMTHbv2kVMTAxxcfFs9srBRZK1Y3OeW1qkbf+T+BMP/RbG1axC+o4/c9hs2fkXw0a/Q6d/vMroVxYCsNvrJ6xSsSzTHxrKva9+yuLvc0Y5pU1sAJ9bbFxctk1mZia7d7vP3J+mzRKoVKkSa9eU5FegYGLj4rLvA4D0tM3UqlU7p01sXM57ZfcuomNiKFeuHDE1agDQpm0SDRo2ZH3KT0HRXRSREVLoFggi0ldEfhSRFBG5tQCb80VkrYisEZG3iqqzQIeoqnVUta73t06u/boBKQ6MrD7ENqp6jaoewM3/DgT/HnkfgQ8SZf2kTgBGqWpL4F6gvJ/NngDrKjZJye1JSVlH6oYNHDhwgGlTJjNg4OAcNv0HDuKNia8BMOOdafToeSoiwoCBg5k2ZTIZGRmkbthASso6ktt3KC2pOVj6Qzonx0VTr1Y1ykRFcN6pzZn71bocNjWqVsiOJG+5sDOvvbcSgDJREUweM4S3Fqxi+qc/BEWvP0nJ7fk5JYXUVPeZvzN1Mv0HDMph03/AYN5+83UA3p0+jR49eiEipKZuIDMzE4BfNm5k3U8/Uq9e/aDobpfUnp/Xp7DR0z192hT65tLdb8AgJr05EYCZM96hm6d7x/bt+HzuNz11w8/8nJJC/foNg6K7KI60ySwikcBzuFZlc+ACEWmey6YxcBuu5ZiIa00WSkAORESGAQ1V9UERiQdOUtXSHLr6DJggIg/jnOPZwCXFOP9PoAqQNfwZAQwBJgEXAou88irAFhEpg4sQg9IZFxUVxRPjnmHwgL74DvoYfulImicmMuaeu2mXlMzAQYMZMfJyLh8xnBYJjYmOjuH1N9yoYfPERM4Zch7tWicSFRnFk089G5QRZgDfQeWGZxYwe+wwIiMjeO29FXyfuoO7RnRn+U9bmPvlOrq3qceYK3qiqixauYnrn3ZpQef2TKBrqzrEVK3AxX1aAXDV2NmsXL8tKNqjoqJ49MmnOXtQP3w+H5dcOpKE5oncP2Y07dol0X/gYIaPuIyrLhtO68QmREfHMH6iCyi++nIRTz72CGXKlCEiIoInnnqWGjVrBk33I48/xZAz++Pz+bho+AgSmify4H2jadsumX4DBnHxpZfxzysuJallU6Kjo3n5Naf7yy8+56H77yEqMorIyEgef/o5onNFvKFASmbqXgcgRVV/dnXKJOBMYK2fzZXAc6r6O4CqFnmzSVGjUSLyLFAG6K6qCSISA8xX1faH9Tby1p9vSoyI3Ahc5u2+rKrj/O1FpCdws6oO9NO5VFUniMg1wNXAFlXt5Q3EPAn0B3YBQ1V1u4j8C/gPsBGX+lNFVUeIyARgjqpOK0p/u6Rk/eLrJUf0GYSCmD4PhVrCYbNtXr6to7An82B4j/wWRkylqGWqmlwSdVWrl6BdbnutUJv3/tVxI4cCGnBpdC9m7YjIEKCvql7h7V8CdFTVUX427wI/AV2ASOAeVX2/sOsGEiF2VtV2IvItgKr+JiJlAzgvIArKD1TVJ4AnCrJX1YXAQr/yUX6vnwGeyecad+Wq63/A//K5xojA34FhGMUlgABxRxEOOL8acv/iRAGNgZ5APPC5iLRQ1T8KqjQQh/i3iERkXUxEauAGKQzDMIqNAJFH3mTeDNTx24/HZZfktvlaVf8GNojIjzgHWWCTLpA8xOeAd4ATROReXP9biefmGYZxnFBEyk2A/YtLgMYi0sBrsQ4DZuWyeRfo5S4pNXGpdD8XVmmREaKqvi4iy4DeXtF5qhqcnAPDMI5JjjRAVNVMERkFzMf1D76qqmtEZAxuLGGWd+wMEVmLy0K5RVV3FlZvoGkqkcDfuGZzuM1uMQzjKEIg4FzDwlDVecC8XGV3+71W4EZvC4ginZuI3AG8jZsOFw+8JSK3BXoBwzCM3ITrTJVAIsSLgSS/lWMeAJYBR2/ehmEYISPU85ULIxCHuDGXXRRFdEwahmEURgmMMpcKBTpEEXkS12e4F1gjIvO9/TM4NNPDMAyj2ISyWVwYhUWIWSPJa4C5fuVfl54cwzCOdUQCX8Ah2BToEFX1lWAKMQzj+CFMA8Si+xBFpBHwAG5FiezVYFS1SSnqMgzjGCZcm8yB5BROAMbj0of6AVNwq8YYhmEUm6w8xCNdD7E0CMQhVlTV+QCqul5V78SbDmMYhnE4SBFbqAgk7SZDXHy7XkT+iVsz8MTSlWUYxrGKSMnMVCkNAnGINwCVgWtxfYnVOLROoWEYRrEJ1z7EQBZ3+MZ7+SfFW7XaMAwjX8LUHxaamD2DvAsuZqOq55SKIsMwjmmOyjxE4NmgqTjKORpXhv9y/KiijcKUDvd+EGoJh8Vnt58aaglhw1HXZFbVj4IpxDCM44dwXUMw0PUQDcMwSoSSWg+xNDCHaBhG0AlTfxi4QxSRcqqaUbSlYRhGwYRzHmIgK2Z3EJFVwDpvv7WIPFPEaYZhGAWStUhsQVuoCKRv82lgILATQFVXYFP3DMM4TASIECl0CxWBNJkjVHVjrmFyXynpMQzjOCAyPFvMATnETSLSAVARiQSuAX4qXVmGYRyrSIijwMIIxCH+C9dsrgv8CnzolRmGYRwWYeoPA5rLvA0YFgQthmEcBwgQFaajzIGsmP0S+cxpVtWrSkWRYRjHPEdthIhrImdRHjgb2FQ6cgzDOOaRo/AxpFmo6mT/fRGZCByds+sNwwg5Lu0m1Cry53Cm7jUA6pW0EMMwjh/C1SEGMlPldxH5zdv+wEWHt5e+NMMwjkVK6iFTItJXRH4UkRQRubUQuyEioiKSXFSdhUaI3rNUWuOeowJwUFWPwtX/DMMIG0pgep6XE/0ccDqwGVgiIrNUdW0uuyq4x598k7eWvBQaIXrOb4aq+rzNnKFhGEdMCUzd6wCkqOrPqnoA92jkM/Oxuw94BNgfkK4AbBaLSLtAKjMMwygK12QufANqishSvy13ml8cObNdNntlh64j0haoo6pzAtVWoEMUkazmdFecU/xRRJaLyLcisjzQCxj588H892nbohmtEhrz+KMP5zmekZHB8IuG0SqhMT27nsLG1FQAdu7cSb8zTuWkmCrceF3wHwPwxcIPOfvUJAb3aMP455/Ic/yNl5/l3N4dOL9vZ/5x4SDSN/+Sfezq4efQvWVdrr3s/GBKBqBrk5rMu7Er79/cjSt6NMhz/NYBTZl+TSemX9OJ927qyjd3u+X+m9Wuwtv/6sjs67vw7rWd6deyVrCl8/EH8+nULpEOrRN4+olH8hzPyMjgyhEX0qF1An17deGXjanZx9asXkm/07rRrUNrepzSlv37AwqUShkhoogN2KGqyX7bi3kqyUt2C1ZEIoAngZuKo6ywPsTFQDvgrOJUeDiISC1gHNAeyABSgXeBwao6sLSvX4CmhcDNqrq0pOv2+XzceN0oZs1bQFx8PN07d6D/wMEkJDTPtnlt/CtUr16dld+vY+qUSdx1x628/uYkypcvz12jx7B2zWrWrlld0tKK1D327pt4/o13OalWHBcP7kWP0/vTsHGzbJumzVvxxuyFVKhQkakTX+aph+5m7HMTABj+j2vZv28f77w1Pqi6IwTuGpzA5a8s5dfd+5lydSc++X4b67ftybZ5eO6P2a8v6lSXhNgqAOz/28etU1axcedeTqhSjndGdWLRuh38uT8zKNp9Ph//vek6ps6cR2xcPGf07ESf/gNp2uzQvfLm6+OpVj2axSu+Z8a0ydw3+nZemvAWmZmZ/PvKETz34nhatGzNbzt3UqZMmaDoLgy3HuIRV7MZqOO3Hw+k++1XAVoAC72FaWoBs0RkcGHf6cJkCYCqrs9vO9x3keciTu0MYKGqNlLV5rhR7JNK6hrhxtIli2nY6GQaNGxI2bJlGXL+UObOnpnDZu7sWVx0yYsFZ5cAACAASURBVKUAnH3OEBZ+8hGqSqVKlejcpSvly5cPuu7V3y0jvl5D4us2oEzZsvQZdA4LF8zNYdO+c3cqVKgIQMu27dm29dA92rFLTypVqhxUzQCt6lTjl5172fz7Pv72KfNWbOHUhBMLtB/QuhbzVmwFIHXHXjbu3AvA9j8z2LnnADGVygZFN8DypUto0LAR9Ru4e+Xsc8/n/bmzc9i8P3c2Qy9wTwgedNa5fL7wE1SVhR99QPPElrRo2RqAmBo1iIyMDJr2wiiBPsQlQGMRaSAiZXHTi2dlHVTVXapaU1Xrq2p94GtcgFVogFOYQzxBRG4saAtEcYD0Av5W1ReyClT1O+BzoLKITBORH0TkTc95IiJ3i8gSEVktIi/6lS8UkbEislhEfhKRbl75CBGZLiLvi8g6Eclud4jIGSLyldcdMFVESv0bm56eRnyd+Oz9uLh40tPS8trEux/AqKgoqlWtxs6dO0tbWqFs/zWdWrGHumlOrB3Htl+3FGj/7pSJdOl5ejCkFcqJVcuzddehpuKvu/dzUrX8f1Biq5cnProiX6/P+1m3jK9GmUjhl9/2lprW3GzdkkZc/KF7pXZsHFvS0wu0iYqKokrVavz2207Wp6xDRDj/rAGc1q0Dz4x7LGi6C0M48gViVTUTGAXMB74HpqjqGhEZIyKDD1dbYU3mSKAy+bfVS5IWwLICjrUFEnGh8BdAF2AR8KyqjoHsmTMDgayfzShV7SAi/YHRQG+vvI1XXwbwo7fq9z7gTqC3qu4Rkf8CNwJjSvYt5iS/wfrcj2UMxCbYFEfT3BmTWbvyW16ePK+0ZRVJvp1NBSRM9G9Vm/mrt+Z5tOwJVcoy9vyW3DZ1FcHMtTjsewUh05fJ4q+/ZP7CL6lQoSLnDupD6zbt6N4z9I9DLYlHCKjqPGBerrK7C7DtGUidhTnELVlOJ4QsVtXNACLyHVAf5xB7ich/gIpADLCGQw5xuvd3mWefxUequsuray1utk11oDnwhXeTlQW+KkqUN+J1FUCdunWL/abi4uLZvGlz9n5a2mZqx8bmtdm8ibj4eDIzM9m1excxMTHFvlZJcmKtOLamH4pkt21J44QT8w4yfLPoE1559jFenjyPsuXKBVNivvy6ez+1/CLCk6qWZ9vu/B8P1K91Le6b+X2OskrlInnh0iSeWrCOFZt2larW3NSOjSdt86F7ZUt6GrVq187XJjbO3St/7t5FdEwMsbFxdOrSjRo1agLQ+4y+rFzxbcgdohC+jyEtsg8xCKwBkgo45n/X+oAoESkPPA8MUdWWwEu4RSdyn+Mjp8PPUxfuPX6gqm28rbmqXl6UYFV9MWv0q2bNE4oyz0NScnvWp6wjdcMGDhw4wLQpk+k/MGeU33/gIN6c+BoAM6ZPo0fPU0MeISa2bsem1PWkbUrl7wMHmD97Oj1O75/D5ofVK3jg9usZ9/IkYg7jsykNVm3eTb2aFYmLrkCZSKF/69p88v22PHb1a1akWoUyfPfLH9llZSKFZy5uy8xv05m/+tdgygagbVIyP/+cwsZUd6/MeGcKffrnHGfs038gk9+eCMDsd9+ha4+eiAi9TjuDtWtWsXfvXjIzM/nyi89p2jQh6O8hD+Ki3MK2UFFYhHhakDR8DDwoIleq6ksAItIe6FGAfZbz2+H19w0Bph3mtb8GnhORk1U1RUQqAvGqWqorgkdFRfH4uGc4a2BffD4fl4wYSfPmidx37920a5fMgEGDuXTk5VwxcjitEhoTHRPDhIlvZ5/fvEkD/ty9mwMHDjBn9kxmzp2fY4S6NHX/d8xjXD38HA76fAw+/2IaNUngf088QPOWbelxen/GPXQXe/fu4T//dgNCteLiGffyJAAuO68vqet/Yt+ePfQ9JYG7xz5D5x69C7tkieA7qNw/63teviyJCBGmL00jZdserul9MqvTdvHJ99sBGNC6NvNW5OwT7duyFskNoqlesQxntXNR/O3TVvPDlj9LXTe4z/zhR8cx9OwB+HwHufCSS2mWkMjD999Dm3ZJ9O0/iIuGj+Tqq0bQoXUC0dHR/N/4NwCoHh3NP6++jj49OyEinHZGX07v27/wCwYBIXxXu5FwmHwiIrG4tJskXEZ5Ki7t5systBsReRZYqqoTROR+3KhSKi45c6Oq3uOfKiMiNT37+iIyAkhW1VFeXXOAx1R1oYicCowFstp2d6rqrEDTbtolJevnXy0pqY8iaPwUpC90aXDhC0X2aoQln90e+r67w+XEqmWXqWqRc4EDoWHzVnrfxML7li9OrlNi1ysOYfGgelVNB/LL1n3Jz2aU3+s7cYMhuevp6fd6B14foqpOACb4HRvo9/pjXP5jgXUZhlGSCBFhutxNWDhEwzCOH8J5UMUcomEYQSfUA4QFYQ7RMIzgIhzVjyE1DMMoMazJbBiG4Yc1mQ3DMDzCdJDZHKJhGMHFNZnD0yOaQzQMI8gEvMRX0DGHaBhG0AlTf2gO0TCM4GJNZsMwjCwEIsI078YcomEYQUcsQjQMw/CazOHpD80hGoYRfGyU2TAMw8OazIZhGDhnGK4rZptDNAwjuAT4qNFQYA7xCPnbd5Ctf+wv2jDMqFE5eA9bL2m+GR36Zz0fDkl3zQ+1hLAhTP2hOUTDMIJLOD9kyhyiYRjBJzz9oTlEwzCCj40yG4ZheFhitmEYRhbmEA3DMFzKTbjOVAnTNScMwziWkSK2gOoQ6SsiP4pIiojcms/xG0VkrYisFJGPRKReUXWaQzQMI/gcoUcUkUjgOaAf0By4QESa5zL7FkhW1VbANOCRouo1h2gYRpBxjxAobAuADkCKqv6sqgeAScCZ/gaq+omq7vV2vwbii6rUHKJhGEGlqODQc4c1RWSp33ZVrmrigE1++5u9soK4HHivKG02qGIYRtAJ4LnMO1Q1ubAq8inTAq51MZAM9CjqouYQDcMIOiUwyLwZqOO3Hw+k572O9AbuAHqoakZRlVqT2TCMoFMCo8xLgMYi0kBEygLDgFk5riHSFvg/YLCqbgukUosQDcMILhJQk7lQVDVTREYB84FI4FVVXSMiY4ClqjoLeBSoDEz1rveLqg4urF5ziIZhBBWhZNZDVNV5wLxcZXf7ve5d3DrNIRqGEXTCc56KOUTDMELAkTaZSwtziIZhBJ0w9YfmEA3DCD7h6hAt7SZEfPrxAk7v3JpTO7bghacfy3N88VeLGNy7E01jq/De7BnZ5WmbfuHM0zsz6NSO9O2exFuvvRRM2Sz8aAG9Oraie/tEnn/q0TzHv/lyEf17daLhSZWZO2t6jmPDzx9My4a1GHnBOcGSm4MPF7xPUqsE2iQ24YlHx+Y5npGRwYiLh9EmsQmnduvExo2pACxbspiuHdvRtWM7unRoy+yZM/KcW5p0a1qT+bd048P/dueqXg3zHL99UDNm3dCFWTd0YcF/urNsjBtLiK1enhnXdWbWDV2Yd1NXLjilTp5zQ4FLrSn8X6gIWoQoIj5gFe7z8AGjVPXLUr5mKm5y947SvE5x8fl83HPrDbw2ZQ61YuM4p083TuszgMZNE7JtYuPq8MhTL/Ly/57Kce4JJ9ViypxPKFeuHHv2/EX/Hsmc1mcAJ9WKDYruu/57PW9Om0ut2DgGn96V3n0H0sRfd3wdHn/2RV58blye868adQP79+7lzddeKXWtufH5fNx0/TW8O3c+cXHx9Orakf4DB9Es4dB6AK9PeJXq0dF8t+Ynpk2ZxOg7bmXCG5NISGzBwi8WExUVxdYtW+jSsS39BgwiKqr0vz4RAvecnciIFxezddd+3rm2Mx+v2UbKtr+ybR6c/UP260u61KN5bFUAtv+ZwdBnv+aA7yAVy0Yy96aufLR2G9t2F5mfXLqE8VP3ghkh7lPVNqraGrgNeCiI1w4IbwWNUmfF8qXUa9CIuvUbULZsWQacNYQP35+Twya+bj2aJbYkIiLnf1HZsmUpV64cAAcyMjh48GAwJAPw3fIl1PfTPejs8/jgvZy669StR0I+ugG6du9FpcpVgiU3B8uWLKZho0Y0aNCQsmXLcs55Q5k7J0ceL/PmzOTCi4YDcNY5Q/h04ceoKhUrVsx2fvsz9gd1QKBV3eps3LGHTb/t42+fMve7LZyWeGKB9gPb1GbOd27Cxt8+5YDP3R9loyLCag1CkcK3UBGqJnNV4HcAcTwqIqtFZJWIDPXKe4pI9rdNRJ4VkRHe61QRuVdElnvnNPPKa4jIAhH5VkT+D7/RfRF5V0SWicga/4niIvKXiIwRkW+AO0Vkht+x00UkZ7uvBPh1azq1Yw/NQ68VG8evW/PMOiqQ9LTNDOjZgW7tmnDVqBuDEh0CbN2STu3YQwuG1I6NY+uWtKBc+0hJT08jLv5QkzEuLo4taTm1b0lPz7aJioqiatVq/LZzJwBLF39Dx3Yt6Zzcmieffj4o0SFArarl2eL3mNutu/ZzUrXy+drGVi9PfEwFvkrZeej8auWZfWMXPrujFy8u/Dn00SFQdIM5dB4xmA6xgoh8JyI/AC8D93nl5wBtgNZAb+BREakdQH07VLUd8D/gZq9sNLBIVdvipvHU9bO/TFWTcJO8rxWRGl55JWC1qnYExgAJInKCd2wkMD73hUXkqqxVOH7bWfzWuGreOejFuQli4+KZu3AxH329ihmT32THtl+LreGwyE93GEUdhZHvZ55Le2E2yR068s3yVXyy6BueeHQs+/cH6Vnc+Xy8+ekEGNgmlvdXbuWg3+Gtu/Yz6Ikv6D32U85Oigub53FbhHioydwM6Au8Lu5u6wq8rao+Vf0V+BRoH0B9WZHbMqC+97o78AaAqs7Fi0I9rhWRFbh10eoAjb1yH/COd44CE4GLRaQ60Il8lgxS1RdVNVlVk2Nq1AzozftTq3YcW9IPRSdb09M4sVYgvwE5OalWLI2bJbDkm1Ltis2mVmwcW9I3Z+9vSU8LWnR6pMTFxZO2+dBqUWlpadSKzak9Ni4u2yYzM5Pdu3cRHROTw6ZpswQqVarE2jWrS180zqHVrn4oIqxVrXyBUd6ANrWZ892WfI9t251Byq9/0b5BTL7Hg0nWTJXj3SFmo6pfATWBEyg4aT2TnPpytxOy7gofOQeH8vx8ikhPXPTZyevD/Navvv2q6vMzHw9cDFwATFXVzKLeT3Fp1TaJjT+nsGljKgcOHGDuu9M4rc+AgM7dkr6Z/fv2AbDrj99ZtvhrGjZqXMRZJUPrtsls+DmFXzzds2dM5fS+gekONe2S27M+JYXU1A0cOHCA6VMn03/AoBw2/QcM5q03Xwfg3enT6N6jFyJCauoGMjPdbfDLxo2s++lH6tWrHxTdqzbton7NSsRHV6BMpDCgTW0+Wpt3nYIGJ1SiaoUovt34R3ZZrWrlKRflvkJVK0TRrn40P2//K8+5oSBcm8whyUP0+vwigZ3AZ8A/ROQ1IAYX5d0ClAGai0g5nPM6DVhURNWfARcB94tIPyDaK68G/K6qe71rn1JQBaqaLiLpwJ3A6Yf5FgslKiqK0Q89wchhg/H5fJx3wXCaNGvOuLFjaNG6Hb37DmTlt0v518hh7P7jDz5eMI+nHr2f9z9bxvp1P/LQ6NsQEVSVK/51HU2btygNmfnqHvPwkww/bxC+gz7Ov/BSmjRrzuMPjaFVm3ac3m8gK5Yv5apLh7Jr1x98OH8eT469nw+/WA7AkIGnsX7dT+zZ8xcdWzbikadeoMeppfIR56v9sSef5pxB/fD5fFx86UgSmifywJjRtG2XRP+Bg7lkxGVcddlw2iQ2ITo6hlcnvgXA118u4snHHqFMmTJIRASPP/UsNWoWv2VwOPgOKve+u5ZXr2xPZIQwbfFmUn79i+vOaMyqzbv42HOOA9vUZm6u6LDRiZW4dVASqi7qeuXTDfy0NTwcYrg+hlQK6o8o8QsdSrsBFxXerqpzvWbzI7hnIyhwv6pO9s55BLcs+DrgADBLVSf4p9OISDLwmKr29PoF38ZFn5/i+ieTgD+Bd3Er6v6Ii0zvUdWFIvKXqlbOpXUYcL2qFug4s2jZpp2+u+CLw/9gQkSZyDC9IwOgeqXw6AcrLkl3zQ+1hMMm5bH+y4pYsDVgWrVN0nkfF97NUyemfIldrzgELUJU1XxTWrx+u1u8Lfex/wD/yae8vt/rpUBP7/VO4Aw/0xv8Xvcr4PqV8ynuCgQ349kwjivC8wfZpu7lQkSWAXuAm0KtxTCORYTwbTKbQ8yFl5pjGEYpEq7ZWuYQDcMIOqEcSS4Mc4iGYQQdixANwzAIffJ1YZhDNAwj6ITrlE9ziIZhBJ3wdIfmEA3DCAFhGiCaQzQMI7gIElZrM/pjjxAwDMPwsAjRMIygE6YBojlEwzCCjBC2TWZziIZhBBXBRpkNwzCysTxEwzAMjzD1h+YQDcMIPmHqD80hGoYRfMK1yRy0Rwgcq4jIdmBjKVVfEyj+c05Dz9GqG45e7aWtu56qnlC0WdGIyPs4vYWxQ1X7lsT1ioM5xDBGRJaG4rkSR8rRqhuOXu1Hq+5ww2aqGIZheJhDNAzD8DCHGN68GGoBh8nRqhuOXu1Hq+6wwvoQDcMwPCxCNAzD8DCHaBiG4WEO0TAMw8McolGiSLhOQSgCEakQag1G6DGHaJQYIiLqjdKJyHki0jnUmgJBRBKAl0Skaai1HC4i0lZEokOt42jHHGIYcrRGWX7O8DRgJPB9aBUFhqp+DxwAbhWRxqHWU1xEpAxwMXCmt39U3j/hgDnEMERVVUT6icj/icgIEWkSak2BIiK9gCuBr1T191DrKQxxRACo6mXAPuCeo9ApZgK/AO3h0A+TUXzMIYYhItIMuB34FUgE/iMiLUKrKn/yiUZ+BfYDzb33EZZkNe9V9aCI1AVQ1X8DaRwlTlFEWonIqZ4DfAFIFJGLQ63raMYSs8MAEakBZKjqXyJyCvAKcKuqzvYc4UCgEfCsqq4IpVZ/cvUZ9gLScQ6xHPAgkApMUdUfQyayCETk38AgYCWwRVXHichzQEVgrKr+EFKBBSAiXXD3xfm4+2UV7nOvqaoviEiEqh4MpcajEYsQQ4yIlAXGADFe0Xe4L+MoAFVdDczERS43ikjlUOjMDz9neD1wP66p/CRQAxfhxgMjwzXaEpFzgaHA5UAzoBWAql4NKHCD1z8XVnhdKGNwn3VPYCtwFvAEcLeItDJneHhYhBgGeCkftYCLVfU+ESkPrAAWqerlnk0isF9V14dQah5EpA9wi6r2FpHngTa49SEfAH4H/guMUdWwW2NQRC7ArSEYD1wADFDVv0WknqpuFJGTVPXX0KrMiYgkA5OB+1V1fK5j5wHdgZ3AfbjfLHOMxcAixDBAVffhosL+InK7qu7HOZZkEXnbs1kTDs4waxDCr+9wJ3CFiFwFNAUuASKBZ3CLgN4QDs6wgJHXXcDbwOWqeobnDP8JXCMiUeHmDAFUdSlO99VZZSJSzjs2FZgE1FFVnznD4mMOMURkfUFFJFZEaqjqGpwz6SEid3lO8hSgndd5HhapFH5fssYiUhFYoaqpuCbnDZ7TXg8sxq167AuN0kPk6us8X0Tu9gZ8PgWeA1JFJElELgP+AUxQ1cwQSs7G7z6Jz8o2UNV2gIrITG8/w69pfwLQy+uXNoqJNZlDQNYXVETOBK4H/gAWAK8CscCzwLeqeqf/lzmUeLmFtVT1TRG5Gvg3sAwog+s7vAPoD7wMjADOUtVNIZKbLyIyHLgWWIqLwO8BtgBZAxR/AA96/bZhg4gMxn2+v+FyO29X1f0ishDIVNXefraNgDLhOhgU9qiqbUHagCi/192Bb3DNyqeAn3ADEeWBk4EPgZNDrdlP76nAQZwTeRpoiBv5fhSY4dnc6e23DLXefPR3AT4G4r39q4DpQH8/m8hQ6yzgPlni3SfX4pz2OKCCd/xrINl7HRFq7Uf7FnIBx8uGGzR5Emjk7Q8GOuIik29w6RPfeA6lWtYNH+rN/0sGJOOilNnefhnPgb8JdPfKwsWpiN/rsrio9Xvgbr/yK3DN5r6h1uunqSawEGjm7Sfhuk76e86vAy4ynwpEh1rvsbZZH2Lw2A7UAW4RkThVnQUsx023GqWqU3BNuUa4G31f6KQ6vH6os73X//SKBwH9RGSoqv6tbgDIh4sY0fDrM4zFNSEnAHcD8SJyBYCqvozL4VsTKq25UTcAtQgYLyInq+oynAPsDzylqotxP0B1OJSqZZQQ5hCDgIhEeo5iKC6iGuOldvwNZOByx07FDUyMVTdIEXJUdSdwjoisws1N3qqqXwB9gYki8qSInI2bTfNlCKVmk8sZ3gTMASaJyD/UjcJ+DLQXkWsAVPV1DZO+ThHJek76y7iR+gUi0tS7T1KAS0RkJO7zv17DIOvgmCPUIeqxvnFo4Kqa9zcCeB6YgMt/i8OlqHwGDAq13izNfro7ARuAd739SO9vVp/iG0BsqDXn8x46AFOAxt57WIOLxME1n58GqodaZz66++Caxmd6+tfj+pRPAm4BPsLlS4Zc67G42ShzEBCRvrjR5DXAMlV9y5seFgU8pKqpIhKjqr+FelQ5V4RVDdgLVAJe915fpKo+L5qpj+tj/ClUevNDRNrjHrr0haqO8spa45z3RFV9RESqqOqfodSZHyLyILBPVe/z9h/AJY33UdV1IlJJVfeE+j45VrEmcynhl8CchMttexn4EegjIrepmx5WGbeQQDlV/Q1Cu1JJLmd4NTAb1+9WATc1rArwqohch+v/3BIOzjB3jqaqLsElXCeKSGuvy2IFLjI8V0Siw8UZ5pNf+gvuvgBAVe/A/RC95eV97vPKzRmWAhYhljDiVk45oKpbRaQObhRzhqre5E3RawzcBtyKm5+cqGGyYEPWggBev+AI3Kj4pbjpbRNUdY0XwdTALTSxKnRqHbmc+Fm4GT+LVTVFRG7DNZdHAyu9yLacqmaEUHIeRKQTrm95K26643u4hPFZQF3gQtwiGV+HTOTxQqjb7MfahpvDuw6o7e3fh7vJE/1sphFeqR49OJTX1gpYDVzl7ccBD+PSgdp7ZWVCrTmf93AD8DnwCPA+cKFXfgvuR6lVqDXm0psVjHTBJYe/BMwHTseN2M/GNfF/CKd75Vjfska1jCMkK1JR1TtEpDZuFHa4qt4lIvuAad6oZypuVDacFk/tAmwQkc3AWpwD+ZeILFLVtSIyDpd0PUhEVqlLtQkbxD2qoIuqdvOiwpOAU0UEVX1URA4QXp83qqrilvA6AzhXVb8UkQG45PyxqjpIRKoCJ6pqSkjFHk+E2iMfaxsu2noe98uegjcCi1uuaT8uh6ylVyah0pn7+kBbXJOtsrd/FzADaO7tn4j7cobDZxyRa/9EXNNyCG4UtiKuuf8dbgWhkGsu4H08jkt0P83bLwf0wyXoXxFqfcfjZoMqJYi4df9eBMYDzXFNoAUiEquqdwM34VIo/gqdSkfuUUpV/RaYB3wjIpVwC7wuBZ7xcuG2qeq2EMnNxtN90Ht9iojUB7ar6i84p/iRqu7FRbpfAB+ESmtBiEhzcStd34RLDB8tItXV9W1+DNyLW/DVCDLWZC5Z/sDNKljvfWmvFpG5wJci0llVnxORGNwshD64BxsFnVwDEZ1xK6R8qqqXicgTuBHkdsBYT+OeUOjMjYg0x43YX+etTHMLbimsN0VkGi6X83MRaYDrBhisYbSEl5d5oLjZP41FxKeqt3gpWNNFZIi61Kv3/H+sjOBho8xHgN+qNWW9ooO4zvDXVHWSZzMI94v/D3XpIGTlHIZKr9/+zcAwYBvO6b2vqq+IyNO4WTUNvGgr5IhbGLUdTtcGXG7kxbhR5AtxfbMv4KLEHsACVV0XErEF4JdrWg43CFQXN3q8UETG49aT7K5hsvTY8Yg5xCPE6wj/B84ZTsb1G74CvIPLHxuEmyGxMtTJtCJSRt00MESkFjARF0XtE5FzgF7Aq6r6rYg8BTytYTA9TEQG4n5UngN242bJdFPVlt7x7jjH/ivwQjhFhVmISDxuJPlpVX3P+xG9BeiMG0T5TEQS1a2LaYQI60M8ArwZEffjlu96Cjdw0gTnBHfhUlYeUtWVEPKk69OB10XkVm/mzE5cAnB3T9t0XBfKcG//ujBxhj1wy12NUtVXVXUabtrdL57TRlU/w/0AVcc9kjMc+R2YC/xTRM5Q1QOq+gDeoyPk0CLBRgixPsQjIxqXBPwRgIj0Bz4BzlPVcVlGYRAZ9sU564m4EdkLcF/Qt4AOIvK7ulVUlgEni1s+P1wcSxLwjKp+JSJlVfUALs/zFuB6EXlEVf+jqh+JyJcaBqsEQY7ulLZAbdxzZt7GW/7fm6DyI7AZ+J+6hTSMEGMRYjHIZ5rVb7jlpKK9L8A63KIN5fyNQuwMY3Cjx/ep6jO4UfDyuNkm7+MWcnhSRF7EzZ6ZGA7O0O+zboAb9AH42/ucfbi1DT8HkkTkYe942ORHes6wL24R2gG4Z52cg3t42GTcE/KmAy97I/xGGGARYoD4/eKfAbTHderfj4tWxgPPev1C5+GWnAoLvE78QcAjIvKpqm4SkUzcytHzROQZnN76wAOqujGUerPw+xGZAdwuIkmqukxEIrwphj4vAX48bnXxkP7w5EZEqgOX4R5g9bG45d0uBH5Tt7jHJ7gZP7+EVKiRA3OIAeI5w564ZNrHgd64Oadn4+b7noXLMbxew2zOqarOFZGDwDIRmY9brOEN79jvuObz8hBKLIxvcAumDvVmniyD7EeIng0MVdWtoRTo6WkEtAZ8qjpTVf8QkV1AS++H6GPPgV/vpdVsCa1iIz9slLkQRCQOaKuqc7z9B4DdqjrW238cFy32VLcoQlguKZWFiPTGPcyqlqpuE5HyGmbT8PLD+3+4HDgN93yR/bhZKedpeCww0QTX/J2PSwN6XVVfEJFLcQn6s1T1CxFphZsCeWm49HUaObE+xP9v725DpK6iOI5/f5mWtj6+UCiENXvQWHI1W3IydwAABUNJREFUjB6opESQUAoMknwhiaaRJIE9YIGFkGAFRUhFgoFRGSWrhFpG+cQGhWgo6kaKSPVCCbRWe2OnF+cM+2/YhxnXmBk7H1jY+c9///c/y3Dm3jv3ntODmMO6HXgulqSAb8IfXjondhr8in9TCHWwA6U3ZrYDn8/6RtLoRgiGAGb2C55cYgX+Pz6JLxeqh2B4Cz4n+EK8H9YCV8h3LW3AM6I/JWljPP44g2H9yiFzN+ITfyy+L3Yg8LikTqAN2CLpMP6FxPVAS5xTV3NYPSmsgdsWi52tQe77PD503lPreykzCphkZlvi8bN4WrfF+Jc+S/H52RbgZKzxzOSudSqHzGUiGLYBq83sA0lD8Qp58/DFwWeB1/B1fBOBlaUhdSOR1GRmdd2jbRSSZuKLxo8Bu8zslfjQOQisK02xpPqXAbEghj8f4kGuLYbN1+LD4kfxRcur8IJKI4FR5olI8xP/f07SA/gc4iDrSj6xAK/b8npNby5VLOcQ/600/GmLx1vxbzEN32WwHg+Ic8zsd4s8dRkMUyzOnw10AEi6AV88XvN5zlS5nEMsMLM9kh6UdAyvdrbXzN6I585K2oqXhzxey/tM9SnWdf4t6Rz+HllmZl/W+r5S5XLI3I0Y/mzDhz9WXJ6irhrLKXUr3j/DzGxTre8lVScDYg9iX/KbwJ1mdrqYKSalSuTccuPJIXMPYvhzATgkaULs6EipYhkMG0/2EPsQ+Q47zezbWt9LSum/lQGxQjn8SenylwExpZRCrkNMKaWQATGllEIGxJRSChkQU68kXZC0X9JBSZ9KGtKPa02TVMotOVvS872cO0LSkxfRxkp5edWKjpeds17SnCraapZ0sNp7TPUrA2Lqy3kzazWzFrxo/eLik3JVv4/MbLOZre7llBFA1QExpf7IgJiqsRuvytcs6bCktXjpgbGSZkhql7QvepJN4BX/JB2RtAcvskQcny/p7fh9jKRNkg7Ez13AamB89E7XxHnLJX0v6UdJLxeutULSUUk78GLvvZK0MK5zQNJnZb3e6ZJ2S+qQ14NG0gBJawptP9Hff2SqTxkQU0UkXQnMpCt7y814qvzJQCeeGn+6mU0BfgCekXQ1Xpx9FnAPXZnFy70F7DSzScAU4BBeAfDn6J0ulxf3uhHPYt6KV9u7V9JteGq2yXjAnVrBy/nczKZGe4fx8gQlzcB9eGbxd+I1LADOmNnUuP5CSeMqaCc1mNy6l/oyWNL++H03sA7PEXmiUEzrDrx2yF5PIckgoB2YAByP8qxI2gAs6qaN+/Fck0TijDOSRpadMyN+SiU7m/AAORTYZGbnoo3NFbymFkmr8GF5E57HsGRj5DP8KbIeTYh2by3MLw6PtjsqaCs1kAyIqS/nzay1eCCCXmfxEPCVmc0tO68VuFQr/wW8ambvlrWx7CLaWA88ZGYHJM0HphWeK7+WRdtLzawYOJHUXGW7qc7lkDldCt8Bd0dSVCQNiVIMR4Bx8hKdAHN7+PuvgSXxtwMkDQP+wHt/Jdvx2jalucnrJI0GdgEPSxoc5R5mVXC/Q4HfJA0EHit77hF57efxeM2co9H2kjgfSTdJuqaCdlKDyR5i6jczOxU9rY8kXRWHXzSzDkmLgC8kncYLRLV0c4mngfci5f4FYImZtUvaG8tatsY84kSgPXqofwLzzGyfpE+A/cAJfFjfl5fwes8n8DnRYuA9CuwExgCLzewvSe/jc4v75I2fwutwp8tM7mVOKaWQQ+aUUgoZEFNKKWRATCmlkAExpZRCBsSUUgoZEFNKKWRATCml8A/DH8WE0NfeHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2,5D evaluation\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "import fire\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from poc_dataset_ACS import BaseDatasetVoxel\n",
    "from mylib.loss import soft_cross_entropy_loss\n",
    "from mylib.utils import MultiAverageMeter, save_model, log_results, to_var, set_seed, \\\n",
    "        to_device, initialize, categorical_to_one_hot, copy_file_backup, redirect_stdout\n",
    "from poc_config_2dpre import POCVoxelConfig as cfg\n",
    "from poc_config_2dpre import POCVoxelEnv as env\n",
    "\n",
    "from unet import UNet\n",
    "from acsconv.models import ACSUNet\n",
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "\n",
    "from mylib.metrics import cal_batch_iou, cal_batch_dice, AUROC_per_case\n",
    "from mylib.loss import soft_dice_loss\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "    \n",
    "train_data = env.data_train\n",
    "test_data = env.data_test\n",
    "\n",
    "train_set = BaseDatasetVoxel(train_data, cfg.train_samples)\n",
    "valid_set = None\n",
    "test_set = BaseDatasetVoxel(test_data, cfg.test_samples)\n",
    "\n",
    "#canal=0\n",
    "PATH=r'C:\\Users\\admin\\Desktop\\cnn-facies-classifier-master\\tmp\\voxel\\Conv2_5D_330samples\\canal_' + format(canal) +'\\model.dat'\n",
    "print(PATH)\n",
    "\n",
    "model = groupmodel[canal]\n",
    "#model=redes[0](4)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model = to_device(model)\n",
    "true=[]\n",
    "truepred=[]\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False,\n",
    "                                pin_memory=(torch.cuda.is_available()), num_workers=cfg.num_workers)\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model,(1,32,32,32))\n",
    "with torch.no_grad():\n",
    "    for z,(x, y) in enumerate(test_loader):\n",
    "        x = to_var(x)\n",
    "        y = to_var(y)\n",
    "            \n",
    "        model.eval()\n",
    "        predit = model(x)\n",
    "        \n",
    "        predit, y = predit.detach().cpu().numpy(), y.detach().cpu().numpy() \n",
    "        predit=np.argmax(predit,1)\n",
    "        y=np.argmax(y,1)\n",
    "\n",
    "\n",
    "        \n",
    "        truepred.append(predit)\n",
    "        true.append(y)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import keras\n",
    "import k3d\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,jaccard_score\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "import src\n",
    "true= np.concatenate(true).ravel()\n",
    "truepred= np.concatenate(truepred).ravel()\n",
    "precision = precision_score(true, truepred, average='weighted')\n",
    "recall = recall_score(true, truepred, average='weighted')\n",
    "f1 = f1_score(true, truepred, average='weighted')\n",
    "jaccard=jaccard_score(true, truepred, average='weighted')\n",
    "\n",
    "classnames = {\n",
    "    0: 'Floodplain',\n",
    "    1: 'Pointbar',\n",
    "    2: 'Channel',\n",
    "    3: 'Boundary',\n",
    "}\n",
    "matrix = confusion_matrix(true, truepred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "print(f'IOU: \\t{jaccard}')\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(f'elapsed:  \\t {elapsed}')\n",
    "\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.classifier = nn.Linear(4, 2)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.modelA(x1)\n",
    "        x2 = self.modelB(x2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet \n",
    "from unet1 import UNet1\n",
    "\n",
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "groupmodels=[]\n",
    "model=UNet(4)\n",
    "for i in range(3):\n",
    "    \n",
    "    model2=Conv2_5dConverter(model,i-3)\n",
    "    #model3=UNet1(4)\n",
    "    #print(model2)\n",
    "    print(i)\n",
    "    print(model2)\n",
    "    groupmodels.append(model2)\n",
    "    \n",
    "#print(groupmodels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=UNet(4)\n",
    "\n",
    "#model3=Conv2_5dConverter(model,-2)\n",
    "\n",
    "\n",
    "#model2=Conv2_5dConverter(model)\n",
    "state_dict_2d=model.state_dict()\n",
    "for key in list(state_dict_2d.keys()):\n",
    "    print(key)\n",
    "    if state_dict_2d[key].dim()==4:\n",
    "        print(state_dict_2d[key].shape)\n",
    "        state_dict_2d[key] = state_dict_2d[key].unsqueeze(i-3)\n",
    "        print(state_dict_2d[key].shape)\n",
    "    #model.state_dict().update(state_dict_2d, strict=True)\n",
    "    #print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acsconv.operators import Conv2_5d\n",
    "model=ACSUNet(4)\n",
    "model2=UNet(4)\n",
    "i=2\n",
    "model2=Conv2_5dConverter(model2,i-3)\n",
    "shape_cp= r'C:\\Users\\admin\\Desktop\\cnn-facies-classifier-master\\RESULTADOS_EQM\\CHANNEL'+ format(i)+ r'\\TRAIN_2D\\model.dat'\n",
    "shape_cp = torch.load(shape_cp)\n",
    "shape_cp.popitem()\n",
    "shape_cp.popitem()\n",
    "for key in list(shape_cp.keys()):\n",
    "    #print(key)\n",
    "    #print(shape_cp[key].shape)\n",
    "    if shape_cp[key].dim()==4:\n",
    "        #print(key)\n",
    "        shape_cp[key] = shape_cp[key].unsqueeze(i-3)\n",
    "        print(shape_cp[key].shape)\n",
    "#print(shape_cp.keys)\n",
    "#incompatible_keys = model2.load_state_dict(shape_cp, strict=False)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
