{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D evaluation\n",
    "import _init_paths\n",
    "\n",
    "import shutil\n",
    "import fire\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics as met\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from unet import UNet\n",
    "from poc_dataset_ACS import BaseDatasetShape\n",
    "from mylib.loss import soft_dice_loss\n",
    "from mylib.utils import MultiAverageMeter, save_model, log_results, to_var, set_seed, \\\n",
    "        to_device, initialize, categorical_to_one_hot, copy_file_backup, redirect_stdout\n",
    "from mylib.metrics import cal_batch_iou, cal_batch_dice, AUROC_per_case\n",
    "from mylib.loss import soft_dice_loss\n",
    "from poc_config import POCShapeConfig as cfg\n",
    "from poc_config import POCShapeEnv as env\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "\n",
    "from unet import UNet\n",
    "from acsconv.models import ACSUNet\n",
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "\n",
    "from mylib.metrics import cal_batch_iou, cal_batch_dice, AUROC_per_case\n",
    "from mylib.loss import soft_dice_loss\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "    \n",
    "train_data = env.data_train\n",
    "test_data = env.data_train\n",
    "view=1 #adicionar o numero da visada de cada rede (de 0 a 2) \n",
    "train_set = BaseDatasetShape(train_data, cfg.train_samples,view)\n",
    "valid_set = None\n",
    "test_set = BaseDatasetShape(test_data, cfg.train_samples,view)\n",
    "\n",
    "PATH=r'C:\\Users\\admin\\Desktop\\Elton\\F3\\ensemblemodels\\canal_'+str(i)+'1\\model.dat'\n",
    "\n",
    "model = UNet(6) #6 é o NUMERO DE CLASSES\n",
    "\n",
    "#initialize(model.modules())\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model = to_device(model)\n",
    "true=[]\n",
    "truepred=[]\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False,\n",
    "                                pin_memory=(torch.cuda.is_available()), num_workers=cfg.num_workers)\n",
    "with torch.no_grad():\n",
    "    for z,(x, y) in enumerate(test_loader):\n",
    "        x = to_var(x)\n",
    "        y = to_var(y)\n",
    "            \n",
    "        model.eval()\n",
    "        predit = model(x)\n",
    "        \n",
    "        predit, y = predit.detach().cpu().numpy(), y.detach().cpu().numpy() \n",
    "        predit=np.argmax(predit,1)\n",
    "        y=np.argmax(y,1)\n",
    "\n",
    "\n",
    "        \n",
    "        truepred.append(predit)\n",
    "        true.append(y)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import keras\n",
    "import k3d\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,jaccard_score,accuracy_score\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "import src\n",
    "true= np.concatenate(true).ravel()\n",
    "truepred= np.concatenate(truepred).ravel()\n",
    "precision = precision_score(true, truepred, average='weighted')\n",
    "recall = recall_score(true, truepred, average='weighted')\n",
    "f1 = f1_score(true, truepred, average='weighted')\n",
    "jaccard=jaccard_score(true, truepred, average='weighted')\n",
    "acc=accuracy_score(true,truepred)\n",
    "\n",
    "\n",
    "classnames = {0:'upper_ns', \n",
    "              1:'middle_ns', \n",
    "              2:'lower_ns',\n",
    "              3:'rijnland_chalk', \n",
    "              4:'scruff', \n",
    "              5:'zechstein'}\n",
    "\n",
    "matrix = confusion_matrix(true, truepred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f'Acurácia: \\t{acc}')\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "print(f'IOU: \\t{jaccard}')\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "#print(f'elapsed:  \\t {elapsed}')\n",
    "\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNET 3D Evaluation\n",
    "\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "import fire\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from poc_dataset_ACS import BaseDatasetVoxel\n",
    "from mylib.loss import soft_cross_entropy_loss\n",
    "from mylib.utils import MultiAverageMeter, save_model, log_results, to_var, set_seed, \\\n",
    "        to_device, initialize, categorical_to_one_hot, copy_file_backup, redirect_stdout\n",
    "from poc_config_3D import POCVoxelConfig as cfg\n",
    "from poc_config_3D import POCVoxelEnv as env\n",
    "\n",
    "from unet import UNet\n",
    "from acsconv.models import ACSUNet\n",
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "\n",
    "from mylib.metrics import cal_batch_iou, cal_batch_dice, AUROC_per_case\n",
    "from mylib.loss import soft_dice_loss\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "    \n",
    "train_data = env.data_train\n",
    "test_data = env.data_test\n",
    "eval_data=env.data_eval\n",
    "eval_data2=env.data_eval2\n",
    "\n",
    "train_set = BaseDatasetVoxel(train_data, cfg.train_samples)\n",
    "valid_set = None\n",
    "test_set = BaseDatasetVoxel(test_data, cfg.test_samples)\n",
    "eval_set= BaseDatasetVoxel(eval_data,cfg.eval_samples)\n",
    "eval_set2= BaseDatasetVoxel(eval_data2,cfg.eval_samples2)\n",
    "\n",
    "#PATH=r'C:\\Users\\admin\\Desktop\\cnn-facies-classifier-master\\tmp\\voxel\\Conv3D_22samples\\model.dat'\n",
    "PATH=os.path.join(cfg.save, r'model.dat')\n",
    "model = UNet(6) #6 é o numero de classes\n",
    "print(PATH)\n",
    "model = Conv3dConverter(model)\n",
    "#initialize(model.modules())\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model = to_device(model)\n",
    "true=[]\n",
    "truepred=[]\n",
    "test_loader = DataLoader(eval_set2, batch_size=1, shuffle=False,\n",
    "                                pin_memory=(torch.cuda.is_available()), num_workers=cfg.num_workers)\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "#summary(model,(1,32,32,32))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for z,(x, y) in enumerate(test_loader):\n",
    "        x = to_var(x)\n",
    "        y = to_var(y)\n",
    "            \n",
    "        model.eval()\n",
    "        predit = model(x)\n",
    "        \n",
    "        predit, y = predit.detach().cpu().numpy(), y.detach().cpu().numpy() \n",
    "        predit=np.argmax(predit,1)\n",
    "        y=np.argmax(y,1)\n",
    "\n",
    "\n",
    "        \n",
    "        truepred.append(predit)\n",
    "        true.append(y)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import keras\n",
    "import k3d\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,jaccard_score, accuracy_score\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "import src\n",
    "true= np.concatenate(true).ravel()\n",
    "truepred= np.concatenate(truepred).ravel()\n",
    "precision = precision_score(true, truepred, average='weighted' )\n",
    "recall = recall_score(true, truepred, average='weighted'  )\n",
    "f1 = f1_score(true, truepred, average='weighted'  )\n",
    "jaccard=jaccard_score(true, truepred, average='weighted' )\n",
    "acc=accuracy_score(true,truepred )\n",
    "\n",
    "\n",
    "classnames = {0:'upper_ns', \n",
    "              1:'middle_ns', \n",
    "              2:'lower_ns',\n",
    "              3:'rijnland_chalk', \n",
    "              4:'scruff', \n",
    "              5:'zechstein'}\n",
    "\n",
    "\n",
    "matrix = confusion_matrix(true, truepred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "print(f'Acurácia: \\t{acc}')\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "print(f'IOU: \\t{jaccard}')\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(f'elapsed:  \\t {elapsed}')\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = {0:'upper_ns', \n",
    "              1:'middle_ns', \n",
    "              2:'lower_ns',\n",
    "              3:'rijnland_chalk', \n",
    "              4:'scruff', \n",
    "              5:'zechstein'}\n",
    "\n",
    "print(f'Acurácia: \\t{acc}')\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "print(f'IOU: \\t{jaccard}')\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(f'elapsed:  \\t {elapsed}')\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truepredensemble1=truepred\n",
    "true1=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truepredensemble2=truepred\n",
    "true2=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=np.append(truepredensemble1,truepredensemble2)\n",
    "finaltrue=np.append(true1,true2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true= finaltrue\n",
    "truepred= final\n",
    "precision = precision_score(true, truepred, average='weighted')\n",
    "recall = recall_score(true, truepred, average='weighted')\n",
    "f1 = f1_score(true, truepred, average='weighted')\n",
    "jaccard=jaccard_score(true, truepred, average='weighted')\n",
    "acc=accuracy_score(true,truepred)\n",
    "\n",
    "\n",
    "classnames = {0:'upper_ns', \n",
    "              1:'middle_ns', \n",
    "              2:'lower_ns',\n",
    "              3:'rijnland_chalk', \n",
    "              4:'scruff', \n",
    "              5:'zechstein'}\n",
    "print(f'Acurácia: \\t{acc}')\n",
    "\n",
    "matrix = confusion_matrix(true, truepred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "print(f'IOU: \\t{jaccard}')\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "#print(f'elapsed:  \\t {elapsed}')\n",
    "\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2,5D my ensemble evaluation\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "import fire\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from poc_dataset_ACS import BaseDatasetVoxel\n",
    "from mylib.loss import soft_cross_entropy_loss\n",
    "from mylib.utils import MultiAverageMeter, save_model, log_results, to_var, set_seed, \\\n",
    "        to_device, initialize, categorical_to_one_hot, copy_file_backup, redirect_stdout\n",
    "from poc_config_2dpre import POCVoxelConfig as cfg\n",
    "from poc_config_2dpre import POCVoxelEnv as env\n",
    "\n",
    "from unet import UNet\n",
    "from acsconv.models import ACSUNet\n",
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "\n",
    "from mylib.metrics import cal_batch_iou, cal_batch_dice, AUROC_per_case\n",
    "from mylib.loss import soft_dice_loss\n",
    "from poc_config_2dpre import mergemodels as merge\n",
    "from unet_ensemble import MyEnsemble\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "    \n",
    "train_data = env.data_train\n",
    "test_data = env.data_test\n",
    "eval_data=env.data_eval\n",
    "eval_data2=env.data_eval2\n",
    "\n",
    "\n",
    "train_set = BaseDatasetVoxel(train_data, cfg.train_samples)\n",
    "valid_set = None\n",
    "test_set = BaseDatasetVoxel(test_data, cfg.test_samples)\n",
    "eval_set= BaseDatasetVoxel(eval_data, cfg.eval_samples)\n",
    "eval_set2= BaseDatasetVoxel(eval_data2,cfg.eval_samples2)\n",
    "\n",
    "\n",
    "PATH=r'C:\\Users\\admin\\Desktop\\Elton\\F3\\ensemblemodels\\Conv2_5D\\canal_4\\model.dat'\n",
    "\n",
    "model = MyEnsemble()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model = to_device(model)\n",
    "true=[]\n",
    "truepred=[]\n",
    "test_loader = DataLoader(eval_set2, batch_size=1, shuffle=False,\n",
    "                                pin_memory=(torch.cuda.is_available()), num_workers=cfg.num_workers)\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "#summary(model,(1,32,32,32))\n",
    "with torch.no_grad():\n",
    "    for z,(x, y) in enumerate(test_loader):\n",
    "        x = to_var(x)\n",
    "        y = to_var(y)\n",
    "            \n",
    "        model.eval()\n",
    "        predit = model(x)\n",
    "        \n",
    "        predit, y = predit.detach().cpu().numpy(), y.detach().cpu().numpy() \n",
    "        predit=np.argmax(predit,1)\n",
    "        y=np.argmax(y,1)\n",
    "\n",
    "\n",
    "        \n",
    "        truepred.append(predit)\n",
    "        true.append(y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import keras\n",
    "import k3d\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,jaccard_score,accuracy_score\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "import src\n",
    "image_size=32\n",
    "def stuff_patches_3D(out_shape,patches,xstep=image_size,ystep=image_size,zstep=image_size):\n",
    "    out = np.zeros(out_shape, patches.dtype)\n",
    "    patch_shape = patches.shape[-3:]\n",
    "    print(out.shape)\n",
    "    print(patch_shape)\n",
    "    patches_6D = np.lib.stride_tricks.as_strided(out, ((out.shape[0]  ) // xstep, (out.shape[1]  ) // ystep,\n",
    "                                                  (out.shape[2]  ) // zstep, patch_shape[0], patch_shape[1], patch_shape[2]),\n",
    "                                                  (out.strides[0] * xstep, out.strides[1] * ystep,out.strides[2] * zstep, out.strides[0], out.strides[1],out.strides[2]))\n",
    "    patches_6D[...] = patches.reshape(patches_6D.shape)\n",
    "    return out\n",
    "\n",
    "#test2=(np.load(r'D:\\Elton\\F3\\data\\test_once\\test2_labels.npy')).shape\n",
    "test1=(np.load(r'D:\\Elton\\F3\\data\\test_once\\test2_labels.npy')).shape\n",
    "\n",
    "pad= tuple((image_size - x%image_size) for x in test1)\n",
    "test2=np.add(test1,pad)\n",
    "\n",
    "true= np.concatenate(true).ravel()\n",
    "truepred= np.concatenate(truepred).ravel()\n",
    "\n",
    "patches=true.reshape(-1,image_size,image_size,image_size)\n",
    "patchesensemble=truepred.reshape(-1,image_size,image_size,image_size)\n",
    "\n",
    "true=stuff_patches_3D((test2),patches)\n",
    "\n",
    "truepred=stuff_patches_3D((test2),patchesensemble)\n",
    "\n",
    "true=true[:-pad[0],:-pad[1],:-pad[2]]\n",
    "truepred=truepred[:-pad[0],:-pad[1],:-pad[2]]\n",
    "\n",
    "patches=true\n",
    "patchesensemble=truepred\n",
    "\n",
    "true= np.concatenate(true).ravel()\n",
    "truepred= np.concatenate(truepred).ravel()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "precision = precision_score(true, truepred, average='weighted')\n",
    "recall = recall_score(true, truepred, average='weighted')\n",
    "f1 = f1_score(true, truepred, average='weighted')\n",
    "jaccard=jaccard_score(true, truepred, average='weighted')\n",
    "acc=accuracy_score(true,truepred)\n",
    "\n",
    "\n",
    "classnames = {0:'upper_ns', \n",
    "              1:'middle_ns', \n",
    "              2:'lower_ns',\n",
    "              3:'rijnland_chalk', \n",
    "              4:'scruff', \n",
    "              5:'zechstein'}\n",
    "print(f'Acurácia: \\t{acc}')\n",
    "\n",
    "matrix = confusion_matrix(true, truepred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "print(f'IOU: \\t{jaccard}')\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "#print(f'elapsed:  \\t {elapsed}')\n",
    "\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")     \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Acurácia: \\t{acc}')\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "print(f'IOU: \\t{jaccard}')\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(f'elapsed:  \\t {elapsed}')\n",
    "\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "truepredensemble1=truepred\n",
    "true1=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truepredensemble2=truepred\n",
    "true2=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=np.append(truepredensemble1,truepredensemble2)\n",
    "finaltrue=np.append(true1,true2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true= finaltrue\n",
    "truepred= final\n",
    "precision = precision_score(true, truepred, average='weighted')\n",
    "recall = recall_score(true, truepred, average='weighted')\n",
    "f1 = f1_score(true, truepred, average='weighted')\n",
    "jaccard=jaccard_score(true, truepred, average='weighted')\n",
    "acc=accuracy_score(true,truepred)\n",
    "\n",
    "\n",
    "classnames = {0:'upper_ns', \n",
    "              1:'middle_ns', \n",
    "              2:'lower_ns',\n",
    "              3:'rijnland_chalk', \n",
    "              4:'scruff', \n",
    "              5:'zechstein'}\n",
    "print(f'Acurácia: \\t{acc}')\n",
    "\n",
    "matrix = confusion_matrix(true, truepred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(f'Precision: \\t{precision}')\n",
    "print(f'Recall: \\t{recall}')\n",
    "print(f'F1-Score: \\t{f1}')\n",
    "print(f'IOU: \\t{jaccard}')\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "#print(f'elapsed:  \\t {elapsed}')\n",
    "\n",
    "src.plot_confusion_matrix(matrix, classnames.values(), title=\"Confusion matrix\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,16))\n",
    "IL=85\n",
    "ax = fig.add_subplot(131)\n",
    "sim = ax.imshow(patches[IL,:,:]);\n",
    "fig.colorbar(sim, ax=ax)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.invert_xaxis()\n",
    "\n",
    "#ax1 = fig.add_subplot(132)\n",
    "#amp = ax1.imshow(finalpredunet[:,IL,:]);\n",
    "#fig.colorbar(amp, ax=ax1)\n",
    "#ax1.set_xticks([])\n",
    "#ax1.set_yticks([])\n",
    "#ax1.invert_xaxis()\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "amp2 = ax2.imshow(patchesensemble[IL,:,:]);\n",
    "fig.colorbar(amp2, ax=ax2)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
